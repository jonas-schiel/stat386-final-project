[
  {
    "objectID": "scripts/merged_data.html",
    "href": "scripts/merged_data.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All Code\n\n\n\n\n\n\nCode\nimport pandas as pd \n\neconomic_df = pd.read_csv(\"../data/raw/econ_data.csv\")\n\n#We need to convert years into election cycle to match datasets with no NAs\neconomic_df['Election Cycle'] = ((economic_df['Year']- 1948) // 4) * 4 + 1948\nelection_df = pd.read_csv(\"../data/raw/election_data.csv\")\n#rename the column year to prepare for a left join on year\nelection_df = election_df.rename(columns={'year': 'Election Cycle'})\n\n\n\n\nCode\n#We use the merge function to combine datasets on year\nmerged_df = economic_df.merge(election_df, on = 'Election Cycle', how = 'left')\nmerged_df.head(40)\n\n\n\n\n\n\n\n\n\nUnnamed: 0_x\nMonth\nYear\nUNRATE\nGDP\nCPI\nPresident\nParty\nElection Cycle\nUnnamed: 0_y\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\n\n\n\n\n0\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n0\nAlabama\n214980\n40930\n19.0\n0.0\n0\n0.0\n0.0\nHarry S Truman\nD\n\n\n1\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n1\nArizona\n177065\n77597\n43.8\n0.0\n95251\n53.8\n4.0\nHarry S Truman\nD\n\n\n2\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n2\nArkansas\n242475\n50959\n21.0\n0.0\n149659\n61.7\n9.0\nHarry S Truman\nD\n\n\n3\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n3\nCalifornia\n4021538\n1895269\n47.1\n0.0\n1913134\n47.6\n25.0\nHarry S Truman\nD\n\n\n4\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n4\nColorado\n515237\n239714\n46.5\n0.0\n267288\n51.9\n6.0\nHarry S Truman\nD\n\n\n5\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n5\nConnecticut\n883518\n437754\n49.5\n8.0\n423297\n47.9\n0.0\nHarry S Truman\nD\n\n\n6\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n6\nDelaware\n139073\n69588\n50.0\n3.0\n67813\n48.8\n0.0\nHarry S Truman\nD\n\n\n7\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n7\nFlorida\n577643\n194280\n33.6\n0.0\n281988\n48.8\n8.0\nHarry S Truman\nD\n\n\n8\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n8\nGeorgia\n418844\n76691\n18.3\n0.0\n254646\n60.8\n12.0\nHarry S Truman\nD\n\n\n9\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n9\nIdaho\n214816\n101514\n47.3\n0.0\n107370\n50.0\n4.0\nHarry S Truman\nD\n\n\n10\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n10\nIllinois\n3984046\n1961103\n49.2\n0.0\n1994715\n50.1\n28.0\nHarry S Truman\nD\n\n\n11\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n11\nIndiana\n1656212\n821079\n49.6\n13.0\n807831\n48.8\n0.0\nHarry S Truman\nD\n\n\n12\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n12\nIowa\n1038264\n494018\n47.6\n0.0\n522380\n50.3\n10.0\nHarry S Truman\nD\n\n\n13\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n13\nKansas\n788819\n423039\n53.6\n8.0\n351902\n44.6\n0.0\nHarry S Truman\nD\n\n\n14\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n14\nKentucky\n822658\n341210\n41.5\n0.0\n466756\n56.7\n11.0\nHarry S Truman\nD\n\n\n15\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n15\nLouisiana\n416336\n72657\n17.5\n0.0\n136344\n32.7\n0.0\nHarry S Truman\nD\n\n\n16\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n16\nMaine\n264787\n150234\n56.7\n5.0\n111916\n42.3\n0.0\nHarry S Truman\nD\n\n\n17\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n17\nMaryland\n596748\n294814\n49.4\n8.0\n286521\n48.0\n0.0\nHarry S Truman\nD\n\n\n18\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n18\nMassachusetts\n2107146\n909370\n43.2\n0.0\n1151788\n54.7\n16.0\nHarry S Truman\nD\n\n\n19\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n19\nMichigan\n2109609\n1038595\n49.2\n19.0\n1003448\n47.6\n0.0\nHarry S Truman\nD\n\n\n20\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n20\nMinnesota\n1212226\n483617\n39.9\n0.0\n692966\n57.2\n11.0\nHarry S Truman\nD\n\n\n21\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n21\nMississippi\n192190\n5043\n2.6\n0.0\n19384\n10.1\n0.0\nHarry S Truman\nD\n\n\n22\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n22\nMissouri\n1578628\n655039\n41.5\n0.0\n917315\n58.1\n15.0\nHarry S Truman\nD\n\n\n23\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n23\nMontana\n224278\n96770\n43.1\n0.0\n119071\n53.1\n4.0\nHarry S Truman\nD\n\n\n24\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n24\nNebraska\n488940\n264774\n54.2\n6.0\n224165\n45.8\n0.0\nHarry S Truman\nD\n\n\n25\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n25\nNevada\n62117\n29357\n47.3\n0.0\n31291\n50.4\n3.0\nHarry S Truman\nD\n\n\n26\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n26\nNew Hampshire\n231440\n121299\n52.4\n4.0\n107995\n46.7\n0.0\nHarry S Truman\nD\n\n\n27\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n27\nNew Jersey\n1949555\n981124\n50.3\n16.0\n895455\n45.9\n0.0\nHarry S Truman\nD\n\n\n28\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n28\nNew Mexico\n187063\n80303\n42.9\n0.0\n105464\n56.4\n4.0\nHarry S Truman\nD\n\n\n29\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n29\nNew York\n6177337\n2841163\n46.0\n47.0\n2780204\n45.0\n0.0\nHarry S Truman\nD\n\n\n30\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n30\nNorth Carolina\n791209\n258572\n32.7\n0.0\n459070\n58.0\n14.0\nHarry S Truman\nD\n\n\n31\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n31\nNorth Dakota\n220716\n115139\n52.2\n4.0\n95812\n43.4\n0.0\nHarry S Truman\nD\n\n\n32\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n32\nOhio\n2936071\n1445684\n49.2\n0.0\n1452791\n49.5\n25.0\nHarry S Truman\nD\n\n\n33\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n33\nOklahoma\n721599\n268817\n37.3\n0.0\n452782\n62.7\n10.0\nHarry S Truman\nD\n\n\n34\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n34\nOregon\n524080\n260904\n49.8\n6.0\n243147\n46.4\n0.0\nHarry S Truman\nD\n\n\n35\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n35\nPennsylvania\n3735348\n1902197\n50.9\n35.0\n1752426\n46.9\n0.0\nHarry S Truman\nD\n\n\n36\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n36\nRhode Island\n327702\n135787\n41.4\n0.0\n188736\n57.6\n4.0\nHarry S Truman\nD\n\n\n37\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n37\nSouth Carolina\n142571\n5386\n3.8\n0.0\n34423\n24.1\n0.0\nHarry S Truman\nD\n\n\n38\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n38\nSouth Dakota\n250105\n129651\n51.8\n4.0\n117653\n47.0\n0.0\nHarry S Truman\nD\n\n\n39\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n1948\n39\nTennessee\n550283\n202914\n36.9\n0.0\n270402\n49.1\n11.0\nHarry S Truman\nD\n\n\n\n\n\n\n\n\n\nCode\nmerged_df = merged_df[['State', 'Total Votes', 'Republican Votes', 'Republican Percentage', 'Republican Electoral',\n                       'Democratic Votes', 'Democratic Percentage', 'Democratic Electoral', 'President Elect', \n                       'Winning Party', 'UNRATE', 'GDP', 'CPI', 'Month', 'Year', 'Election Cycle']]\n\n\n\n\nCode\n\nmerged_df.head()\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nUNRATE\nGDP\nCPI\nMonth\nYear\nElection Cycle\n\n\n\n\n0\nAlabama\n214980\n40930\n19.0\n0.0\n0\n0.0\n0.0\nHarry S Truman\nD\n3.4\n265.742\n23.68\nJanuary\n1948\n1948\n\n\n1\nArizona\n177065\n77597\n43.8\n0.0\n95251\n53.8\n4.0\nHarry S Truman\nD\n3.4\n265.742\n23.68\nJanuary\n1948\n1948\n\n\n2\nArkansas\n242475\n50959\n21.0\n0.0\n149659\n61.7\n9.0\nHarry S Truman\nD\n3.4\n265.742\n23.68\nJanuary\n1948\n1948\n\n\n3\nCalifornia\n4021538\n1895269\n47.1\n0.0\n1913134\n47.6\n25.0\nHarry S Truman\nD\n3.4\n265.742\n23.68\nJanuary\n1948\n1948\n\n\n4\nColorado\n515237\n239714\n46.5\n0.0\n267288\n51.9\n6.0\nHarry S Truman\nD\n3.4\n265.742\n23.68\nJanuary\n1948\n1948\n\n\n\n\n\n\n\n\n\nCode\nmerged_df.to_csv(\"../data/processed/economic_election_data.csv\")"
  },
  {
    "objectID": "scripts/president_data.html",
    "href": "scripts/president_data.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All Code\n\n\n\n\n\n\nCode\nfrom bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\n\n\n1948 Table\n\n\nCode\n#Because of inconsistencies in how the data is formatted we will actually need to scrape and clean tables one at a time\n\ndf_1948 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1948\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1948\n\n#create the dataframe using append and concat\ndf_1948.append(dataframe)\ndf_1948 = pd.concat(df_1948, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1948[\"State\"] = df_1948[0]\ndf_1948[\"Total Votes\"] = df_1948[1]\ndf_1948[\"Republican Votes\"] = df_1948[5]\ndf_1948[\"Republican Percentage\"] = df_1948[6]\ndf_1948[\"Republican Electoral\"] = df_1948[7]\ndf_1948[\"Democratic Votes\"] = df_1948[2]\ndf_1948[\"Democratic Percentage\"] = df_1948[3]\ndf_1948[\"Democratic Electoral\"] = df_1948[4]\ndf_1948[\"President Elect\"] = str(\"Harry S Truman\")\ndf_1948[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_1948 = df_1948[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 11 rows of the data\ndf_1948 = df_1948.iloc[12:].reset_index(drop = True)\n#Drop every row below 48\ndf_1948 = df_1948.iloc[:48].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_1948.head(), df_1948.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/2096849562.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n214980\n40930\n19.0\nNaN\n--\n0.0\nNaN\nHarry S Truman\nD\n1948\n\n\n1\nArizona\n177065\n77597\n43.8\nNaN\n95251\n53.8\n4\nHarry S Truman\nD\n1948\n\n\n2\nArkansas\n242475\n50959\n21.0\nNaN\n149659\n61.7\n9\nHarry S Truman\nD\n1948\n\n\n3\nCalifornia\n4021538\n1895269\n47.1\nNaN\n1913134\n47.6\n25\nHarry S Truman\nD\n1948\n\n\n4\nColorado\n515237\n239714\n46.5\nNaN\n267288\n51.9\n6\nHarry S Truman\nD\n1948\n\n\n43\nVirginia\n419256\n172070\n41.0\nNaN\n200786\n47.9\n11\nHarry S Truman\nD\n1948\n\n\n44\nWashington\n905058\n386314\n42.7\nNaN\n476165\n52.6\n8\nHarry S Truman\nD\n1948\n\n\n45\nWest Virginia\n748750\n316251\n42.2\nNaN\n429188\n57.3\n8\nHarry S Truman\nD\n1948\n\n\n46\nWisconsin\n1276800\n590959\n46.3\nNaN\n647310\n50.7\n12\nHarry S Truman\nD\n1948\n\n\n47\nWyoming\n101425\n47947\n47.3\nNaN\n52354\n51.6\n3\nHarry S Truman\nD\n1948\n\n\n\n\n\n\n\n1952 Table\n\n\nCode\n#Because of inconsistencies in how the data is formatted we will actually need to scrape and clean tables one at a time\n\ndf_1952 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1952\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1952\n\ndf_1952.append(dataframe)\ndf_1952 = pd.concat(df_1952, ignore_index = True)\n\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/1941760809.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\nCode\npd.concat([df_1948.head(), df_1948.tail(10)])\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n214980\n40930\n19.0\nNaN\n--\n0.0\nNaN\nHarry S Truman\nD\n1948\n\n\n1\nArizona\n177065\n77597\n43.8\nNaN\n95251\n53.8\n4\nHarry S Truman\nD\n1948\n\n\n2\nArkansas\n242475\n50959\n21.0\nNaN\n149659\n61.7\n9\nHarry S Truman\nD\n1948\n\n\n3\nCalifornia\n4021538\n1895269\n47.1\nNaN\n1913134\n47.6\n25\nHarry S Truman\nD\n1948\n\n\n4\nColorado\n515237\n239714\n46.5\nNaN\n267288\n51.9\n6\nHarry S Truman\nD\n1948\n\n\n38\nSouth Dakota\n250105\n129651\n51.8\n4\n117653\n47.0\nNaN\nHarry S Truman\nD\n1948\n\n\n39\nTennessee\n550283\n202914\n36.9\nNaN\n270402\n49.1\n11\nHarry S Truman\nD\n1948\n\n\n40\nTexas\n1147245\n282240\n24.6\nNaN\n750700\n65.4\n23\nHarry S Truman\nD\n1948\n\n\n41\nUtah\n276306\n124402\n45.0\nNaN\n149151\n54.0\n4\nHarry S Truman\nD\n1948\n\n\n42\nVermont\n123382\n75926\n61.5\n3\n45557\n36.9\nNaN\nHarry S Truman\nD\n1948\n\n\n43\nVirginia\n419256\n172070\n41.0\nNaN\n200786\n47.9\n11\nHarry S Truman\nD\n1948\n\n\n44\nWashington\n905058\n386314\n42.7\nNaN\n476165\n52.6\n8\nHarry S Truman\nD\n1948\n\n\n45\nWest Virginia\n748750\n316251\n42.2\nNaN\n429188\n57.3\n8\nHarry S Truman\nD\n1948\n\n\n46\nWisconsin\n1276800\n590959\n46.3\nNaN\n647310\n50.7\n12\nHarry S Truman\nD\n1948\n\n\n47\nWyoming\n101425\n47947\n47.3\nNaN\n52354\n51.6\n3\nHarry S Truman\nD\n1948\n\n\n\n\n\n\n\n\n\nCode\ndf_1952[\"State\"] = df_1952[0]\ndf_1952[\"Total Votes\"] = df_1952[1]\ndf_1952[\"Republican Votes\"] = df_1952[2]\ndf_1952[\"Republican Percentage\"] = df_1952[3]\ndf_1952[\"Republican Electoral\"] = df_1952[4]\ndf_1952[\"Democratic Votes\"] = df_1952[5]\ndf_1952[\"Democratic Percentage\"] = df_1952[6]\ndf_1952[\"Democratic Electoral\"] = df_1952[7]\ndf_1952[\"President Elect\"] = str(\"Dwight D. Eisenhower\")\ndf_1952[\"Winning Party\"] = str(\"R\")\n\ndf_1952 = df_1952[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\ndf_1952 = df_1952.iloc[11:].reset_index(drop = True)\ndf_1952 = df_1952.iloc[:48].reset_index(drop = True)\n\n\n\n\nCode\npd.concat([df_1952.head(), df_1952.tail()])\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n426120\n149231\n35.0\nNaN\n275075\n64.6\n11\nDwight D. Eisenhower\nR\n1952\n\n\n1\nArizona\n260570\n152042\n58.3\n4\n108528\n41.7\nNaN\nDwight D. Eisenhower\nR\n1952\n\n\n2\nArkansas\n404800\n177155\n43.8\nNaN\n226300\n55.9\n8\nDwight D. Eisenhower\nR\n1952\n\n\n3\nCalifornia\n5141849\n2897310\n56.3\n32\n2197548\n42.7\nNaN\nDwight D. Eisenhower\nR\n1952\n\n\n4\nColorado\n630103\n379782\n60.3\n6\n245504\n39.0\nNaN\nDwight D. Eisenhower\nR\n1952\n\n\n43\nVirginia\n619689\n349037\n56.3\n12\n268677\n43.4\nNaN\nDwight D. Eisenhower\nR\n1952\n\n\n44\nWashington\n1102708\n599107\n54.3\n9\n492845\n44.7\nNaN\nDwight D. Eisenhower\nR\n1952\n\n\n45\nWest Virginia\n873548\n419970\n48.1\nNaN\n453578\n51.9\n8\nDwight D. Eisenhower\nR\n1952\n\n\n46\nWisconsin\n1607370\n979744\n61.0\n12\n622175\n38.7\nNaN\nDwight D. Eisenhower\nR\n1952\n\n\n47\nWyoming\n129253\n81049\n62.7\n3\n47934\n37.1\nNaN\nDwight D. Eisenhower\nR\n1952\n\n\n\n\n\n\n\n1954 table\n\n\nCode\n\n\ndf_1956 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1956\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1956\n\n#create the dataframe using append and concat\ndf_1956.append(dataframe)\ndf_1956 = pd.concat(df_1956, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1956[\"State\"] = df_1956[0]\ndf_1956[\"Total Votes\"] = df_1956[1]\ndf_1956[\"Republican Votes\"] = df_1956[2]\ndf_1956[\"Republican Percentage\"] = df_1956[3]\ndf_1956[\"Republican Electoral\"] = df_1956[4]\ndf_1956[\"Democratic Votes\"] = df_1956[5]\ndf_1956[\"Democratic Percentage\"] = df_1956[6]\ndf_1956[\"Democratic Electoral\"] = df_1956[7]\ndf_1956[\"President Elect\"] = str(\"Dwight D. Eisenhower\")\ndf_1956[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_1956 = df_1956[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 10 rows of the data\ndf_1956 = df_1956.iloc[11:].reset_index(drop = True)\n#Drop every row below 48\ndf_1956 = df_1956.iloc[:48].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_1956.head(), df_1956.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/3994886160.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama*\n496861\n195694\n39.4\nNaN\n280844\n56.5\n10*\nDwight D. Eisenhower\nR\n1956\n\n\n1\nArizona\n290173\n176990\n61.0\n4\n112880\n38.9\nNaN\nDwight D. Eisenhower\nR\n1956\n\n\n2\nArkansas\n406572\n186287\n45.8\nNaN\n213277\n52.5\n8\nDwight D. Eisenhower\nR\n1956\n\n\n3\nCalifornia\n5466355\n3027668\n55.4\n32\n2420135\n44.3\nNaN\nDwight D. Eisenhower\nR\n1956\n\n\n4\nColorado\n657074\n394479\n60.0\n6\n257997\n39.3\nNaN\nDwight D. Eisenhower\nR\n1956\n\n\n43\nVirginia\n697978\n386459\n55.4\n12\n267760\n38.4\nNaN\nDwight D. Eisenhower\nR\n1956\n\n\n44\nWashington\n1150889\n620430\n53.9\n9\n523002\n45.4\nNaN\nDwight D. Eisenhower\nR\n1956\n\n\n45\nWest Virginia\n830831\n449297\n54.1\n8\n381534\n45.9\nNaN\nDwight D. Eisenhower\nR\n1956\n\n\n46\nWisconsin\n1550558\n954844\n61.6\n12\n586768\n37.8\nNaN\nDwight D. Eisenhower\nR\n1956\n\n\n47\nWyoming\n124127\n74573\n60.1\n3\n49554\n39.9\nNaN\nDwight D. Eisenhower\nR\n1956\n\n\n\n\n\n\n\n1960 table\n\n\nCode\n\ndf_1960 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1960\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1960\n\n#create the dataframe using append and concat\ndf_1960.append(dataframe)\ndf_1960 = pd.concat(df_1960, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1960[\"State\"] = df_1960[0]\ndf_1960[\"Total Votes\"] = df_1960[1]\ndf_1960[\"Republican Votes\"] = df_1960[5]\ndf_1960[\"Republican Percentage\"] = df_1960[6]\ndf_1960[\"Republican Electoral\"] = df_1960[7]\ndf_1960[\"Democratic Votes\"] = df_1960[2]\ndf_1960[\"Democratic Percentage\"] = df_1960[3]\ndf_1960[\"Democratic Electoral\"] = df_1960[4]\ndf_1960[\"President Elect\"] = str(\"John F. Kennedy\")\ndf_1960[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_1960 = df_1960[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 10 rows of the data\ndf_1960 = df_1960.iloc[9:].reset_index(drop = True)\n#Drop every row below 48\ndf_1960 = df_1960.iloc[:50].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_1960.head(15), df_1960.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/2337687889.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama*\n570225\n237981\n41.7\nNaN\n324050\n56.8\n5*\nJohn F. Kennedy\nD\n1960\n\n\n1\nAlaska\n60762\n30953\n50.9\n3\n29809\n49.1\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n2\nArizona\n398491\n221241\n55.5\n4\n176781\n44.4\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n3\nArkansas\n428509\n184508\n43.1\nNaN\n215049\n50.2\n8\nJohn F. Kennedy\nD\n1960\n\n\n4\nCalifornia\n6506578\n3259722\n50.1\n32\n3224099\n49.6\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n5\nColorado\n736236\n402242\n54.6\n6\n330629\n44.9\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n6\nConnecticut\n1222883\n565813\n46.3\nNaN\n657055\n53.7\n8\nJohn F. Kennedy\nD\n1960\n\n\n7\nDelaware\n196683\n96373\n49.0\nNaN\n99590\n50.6\n3\nJohn F. Kennedy\nD\n1960\n\n\n8\nFlorida\n1544176\n795476\n51.5\n10\n748700\n48.5\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n9\nGeorgia\n733349\n274472\n37.4\nNaN\n458638\n62.5\n12\nJohn F. Kennedy\nD\n1960\n\n\n10\nHawaii\n184705\n92295\n50.0\nNaN\n92410\n50.0\n3\nJohn F. Kennedy\nD\n1960\n\n\n11\nIdaho\n300450\n161597\n53.8\n4\n138853\n46.2\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n12\nIllinois\n4757409\n2368988\n49.8\nNaN\n2377846\n50.0\n27\nJohn F. Kennedy\nD\n1960\n\n\n13\nIndiana\n2135360\n1175120\n55.0\n13\n952358\n44.6\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n14\nIowa\n1273810\n722381\n56.7\n10\n550565\n43.2\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n45\nVirginia\n771449\n404521\n52.4\n12\n362327\n47.0\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n46\nWashington\n1241572\n629273\n50.7\n9\n599298\n48.3\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n47\nWest Virginia\n837781\n395995\n47.3\nNaN\n441786\n52.7\n8\nJohn F. Kennedy\nD\n1960\n\n\n48\nWisconsin\n1729082\n895175\n51.8\n12\n830805\n48.0\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n49\nWyoming\n140782\n77451\n55.0\n3\n63331\n45.0\nNaN\nJohn F. Kennedy\nD\n1960\n\n\n\n\n\n\n\n1964 Table\n\n\nCode\ndf_1964 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1964\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1964\n\n#create the dataframe using append and concat\ndf_1964.append(dataframe)\ndf_1964 = pd.concat(df_1964, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1964[\"State\"] = df_1964[0]\ndf_1964[\"Total Votes\"] = df_1964[1]\ndf_1964[\"Republican Votes\"] = df_1964[5]\ndf_1964[\"Republican Percentage\"] = df_1964[6]\ndf_1964[\"Republican Electoral\"] = df_1964[7]\ndf_1964[\"Democratic Votes\"] = df_1964[2]\ndf_1964[\"Democratic Percentage\"] = df_1964[3]\ndf_1964[\"Democratic Electoral\"] = df_1964[4]\ndf_1964[\"President Elect\"] = str(\"Lyndon B. Johnson\")\ndf_1964[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_1964 = df_1964[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 9 rows of the data\ndf_1964 = df_1964.iloc[10:].reset_index(drop = True)\n#Drop every row below 50\ndf_1964 = df_1964.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_1964.head(), df_1964.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/1709304266.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n689818\n479085\n69.5\n10\n--\n0.0\nNaN\nLyndon B. Johnson\nD\n1964\n\n\n1\nAlaska\n67259\n22930\n34.1\nNaN\n44329\n65.9\n3\nLyndon B. Johnson\nD\n1964\n\n\n2\nArizona\n480770\n242535\n50.4\n5\n237753\n49.5\nNaN\nLyndon B. Johnson\nD\n1964\n\n\n3\nArkansas\n560426\n243264\n43.4\nNaN\n314197\n56.1\n6\nLyndon B. Johnson\nD\n1964\n\n\n4\nCalifornia\n7057586\n2879108\n40.8\nNaN\n4171877\n59.1\n40\nLyndon B. Johnson\nD\n1964\n\n\n46\nVirginia\n1042267\n481334\n46.2\nNaN\n558038\n53.5\n12\nLyndon B. Johnson\nD\n1964\n\n\n47\nWashington\n1258556\n470366\n37.4\nNaN\n779881\n62.0\n9\nLyndon B. Johnson\nD\n1964\n\n\n48\nWest Virginia\n792040\n253953\n32.1\nNaN\n538087\n67.9\n7\nLyndon B. Johnson\nD\n1964\n\n\n49\nWisconsin\n1691815\n638495\n37.7\nNaN\n1050424\n62.1\n12\nLyndon B. Johnson\nD\n1964\n\n\n50\nWyoming\n142716\n61998\n43.4\nNaN\n80718\n56.6\n3\nLyndon B. Johnson\nD\n1964\n\n\n\n\n\n\n\n1964 Table\n\n\nCode\ndf_1968 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1968\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1968\n\n#create the dataframe using append and concat\ndf_1968.append(dataframe)\ndf_1968 = pd.concat(df_1968, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1968[\"State\"] = df_1968[0]\ndf_1968[\"Total Votes\"] = df_1968[1]\ndf_1968[\"Republican Votes\"] = df_1968[2]\ndf_1968[\"Republican Percentage\"] = df_1968[3]\ndf_1968[\"Republican Electoral\"] = df_1968[4]\ndf_1968[\"Democratic Votes\"] = df_1968[5]\ndf_1968[\"Democratic Percentage\"] = df_1968[6]\ndf_1968[\"Democratic Electoral\"] = df_1968[7]\ndf_1968[\"President Elect\"] = str(\"Richard Nixon\")\ndf_1968[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_1968 = df_1968[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 9 rows of the data\ndf_1968 = df_1968.iloc[9:].reset_index(drop = True)\n#Drop every row below 48\ndf_1968 = df_1968.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data\npd.concat([df_1968.head(), df_1968.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/4262740232.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1049922\n146923\n14.0\nNaN\n196579\n18.7\nNaN\nRichard Nixon\nR\n1968\n\n\n1\nAlaska\n83035\n37600\n45.3\n3\n35411\n42.6\nNaN\nRichard Nixon\nR\n1968\n\n\n2\nArizona\n486936\n266721\n54.8\n5\n170514\n35.0\nNaN\nRichard Nixon\nR\n1968\n\n\n3\nArkansas\n619969\n190759\n30.8\nNaN\n188228\n30.4\nNaN\nRichard Nixon\nR\n1968\n\n\n4\nCalifornia\n7251587\n3467664\n47.8\n40\n3244318\n44.7\nNaN\nRichard Nixon\nR\n1968\n\n\n46\nVirginia\n1361491\n590319\n43.4\n12\n442387\n32.5\nNaN\nRichard Nixon\nR\n1968\n\n\n47\nWashington\n1304281\n588510\n45.1\nNaN\n616037\n47.2\n9\nRichard Nixon\nR\n1968\n\n\n48\nWest Virginia\n754206\n307555\n40.8\nNaN\n374091\n49.6\n7\nRichard Nixon\nR\n1968\n\n\n49\nWisconsin\n1691538\n809997\n47.9\n12\n748804\n44.3\nNaN\nRichard Nixon\nR\n1968\n\n\n50\nWyoming\n127205\n70927\n55.8\n3\n45173\n35.5\nNaN\nRichard Nixon\nR\n1968\n\n\n\n\n\n\n\n1972 Table\n\n\nCode\ndf_1972 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1972\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1972\n\n#create the dataframe using append and concat\ndf_1972.append(dataframe)\ndf_1972 = pd.concat(df_1972, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1972[\"State\"] = df_1972[0]\ndf_1972[\"Total Votes\"] = df_1972[1]\ndf_1972[\"Republican Votes\"] = df_1972[2]\ndf_1972[\"Republican Percentage\"] = df_1972[3]\ndf_1972[\"Republican Electoral\"] = df_1972[4]\ndf_1972[\"Democratic Votes\"] = df_1972[5]\ndf_1972[\"Democratic Percentage\"] = df_1972[6]\ndf_1972[\"Democratic Electoral\"] = df_1972[7]\ndf_1972[\"President Elect\"] = str(\"Richard Nixon\")\ndf_1972[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_1972 = df_1972[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 9 rows of the data\ndf_1972 = df_1972.iloc[10:].reset_index(drop = True)\n#Drop every row below 50\ndf_1972 = df_1972.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data\npd.concat([df_1972.head(), df_1972.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/3228363382.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1006111\n728701\n72.4\n9\n256923\n25.5\nNaN\nRichard Nixon\nR\n1972\n\n\n1\nAlaska\n95219\n55349\n58.1\n3\n32967\n34.6\nNaN\nRichard Nixon\nR\n1972\n\n\n2\nArizona\n622926\n402812\n64.7\n6\n198540\n31.9\nNaN\nRichard Nixon\nR\n1972\n\n\n3\nArkansas\n651320\n448541\n68.9\n6\n199892\n30.7\nNaN\nRichard Nixon\nR\n1972\n\n\n4\nCalifornia\n8367862\n4602096\n55.0\n45\n3475847\n41.5\nNaN\nRichard Nixon\nR\n1972\n\n\n46\nVirginia*\n1457019\n988493\n67.8\n11*\n438887\n30.1\nNaN\nRichard Nixon\nR\n1972\n\n\n47\nWashington\n1470847\n837135\n56.9\n9\n568334\n38.6\nNaN\nRichard Nixon\nR\n1972\n\n\n48\nWest Virginia\n762399\n484964\n63.6\n6\n277435\n36.4\nNaN\nRichard Nixon\nR\n1972\n\n\n49\nWisconsin\n1852890\n989430\n53.4\n11\n810174\n43.7\nNaN\nRichard Nixon\nR\n1972\n\n\n50\nWyoming\n145570\n100464\n69.0\n3\n44358\n30.5\nNaN\nRichard Nixon\nR\n1972\n\n\n\n\n\n\n\n1976 Table\n\n\nCode\ndf_1976 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1976\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. For this dev code there are two tables so we do\n    #have to make sure to grab the second table\ntables = soup.find_all(\"table\")\n#This grabs the second table\ntable = tables[1]\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1976\n\n#create the dataframe using append and concat\ndf_1976.append(dataframe)\ndf_1976 = pd.concat(df_1976, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1976[\"State\"] = df_1976[0]\ndf_1976[\"Total Votes\"] = df_1976[1]\ndf_1976[\"Republican Votes\"] = df_1976[2]\ndf_1976[\"Republican Percentage\"] = df_1976[3]\ndf_1976[\"Republican Electoral\"] = df_1976[4]\ndf_1976[\"Democratic Votes\"] = df_1976[5]\ndf_1976[\"Democratic Percentage\"] = df_1976[6]\ndf_1976[\"Democratic Electoral\"] = df_1976[7]\ndf_1976[\"President Elect\"] = str(\"Jimmy Carter\")\ndf_1976[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_1976 = df_1976[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 4 rows of the data\ndf_1976 = df_1976.iloc[5:].reset_index(drop = True)\n#Drop every row below 50\ndf_1976 = df_1976.iloc[:51].reset_index(drop = True)\n\n# #Check top and bottom \npd.concat([df_1976.head(15), df_1976.tail(15)])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/3905204104.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1182850\n659170\n55.7\n9\n504070\n42.6\nNaN\nJimmy Carter\nD\n1976\n\n\n1\nAlaska\n123574\n44058\n35.7\nNaN\n71555\n57.9\n3\nJimmy Carter\nD\n1976\n\n\n2\nArizona\n742719\n295602\n39.8\nNaN\n418642\n56.4\n6\nJimmy Carter\nD\n1976\n\n\n3\nArkansas\n767535\n498604\n65.0\n6\n267903\n34.9\nNaN\nJimmy Carter\nD\n1976\n\n\n4\nCalifornia\n7867117\n3742284\n47.6\nNaN\n3882244\n49.3\n45\nJimmy Carter\nD\n1976\n\n\n5\nColorado\n1081554\n460353\n42.6\nNaN\n584367\n54.0\n7\nJimmy Carter\nD\n1976\n\n\n6\nConnecticut\n1381526\n647895\n46.9\nNaN\n719261\n52.1\n8\nJimmy Carter\nD\n1976\n\n\n7\nDelaware\n235834\n122596\n52.0\n3\n109831\n46.6\nNaN\nJimmy Carter\nD\n1976\n\n\n8\nDist. of Col.\n168830\n137818\n81.6\n3\n27873\n16.5\nNaN\nJimmy Carter\nD\n1976\n\n\n9\nFlorida\n3150631\n1636000\n51.9\n17\n1469531\n46.6\nNaN\nJimmy Carter\nD\n1976\n\n\n10\nGeorgia\n1467458\n979409\n66.7\n12\n483743\n33.0\nNaN\nJimmy Carter\nD\n1976\n\n\n11\nHawaii\n291301\n147375\n50.6\n4\n140003\n48.1\nNaN\nJimmy Carter\nD\n1976\n\n\n12\nIdaho\n344071\n126549\n36.8\nNaN\n204151\n59.3\n4\nJimmy Carter\nD\n1976\n\n\n13\nIllinois\n4718914\n2271295\n48.1\nNaN\n2364269\n50.1\n26\nJimmy Carter\nD\n1976\n\n\n14\nIndiana\n2220362\n1014714\n45.7\nNaN\n1183958\n53.3\n13\nJimmy Carter\nD\n1976\n\n\n36\nOklahoma\n1092251\n532442\n48.7\nNaN\n545708\n50.0\n8\nJimmy Carter\nD\n1976\n\n\n37\nOregon\n1029876\n490407\n47.6\nNaN\n492120\n47.8\n6\nJimmy Carter\nD\n1976\n\n\n38\nPennsylvania\n4620787\n2328677\n50.4\n27\n2205604\n47.7\nNaN\nJimmy Carter\nD\n1976\n\n\n39\nRhode Island\n411170\n227636\n55.4\n4\n181249\n44.1\nNaN\nJimmy Carter\nD\n1976\n\n\n40\nSouth Carolina\n802583\n450807\n56.2\n8\n346149\n43.1\nNaN\nJimmy Carter\nD\n1976\n\n\n41\nSouth Dakota\n300678\n147068\n48.9\nNaN\n151505\n50.4\n4\nJimmy Carter\nD\n1976\n\n\n42\nTennessee\n1476345\n825879\n55.9\n10\n633969\n42.9\nNaN\nJimmy Carter\nD\n1976\n\n\n43\nTexas\n4071884\n2082319\n51.1\n26\n1953300\n48.0\nNaN\nJimmy Carter\nD\n1976\n\n\n44\nUtah\n541198\n182110\n33.6\nNaN\n337908\n62.4\n4\nJimmy Carter\nD\n1976\n\n\n45\nVermont\n187765\n80954\n43.1\nNaN\n102085\n54.4\n3\nJimmy Carter\nD\n1976\n\n\n46\nVirginia\n1697094\n813896\n48.0\nNaN\n836554\n49.3\n12\nJimmy Carter\nD\n1976\n\n\n47\nWashington*\n1555534\n717323\n46.1\nNaN\n777732\n50.0\n8*\nJimmy Carter\nD\n1976\n\n\n48\nWest Virginia\n750964\n435914\n58.0\n6\n314760\n41.9\nNaN\nJimmy Carter\nD\n1976\n\n\n49\nWisconsin\n2104175\n1040232\n49.4\n11\n1004987\n47.8\nNaN\nJimmy Carter\nD\n1976\n\n\n50\nWyoming\n156343\n62239\n39.8\nNaN\n92717\n59.3\n3\nJimmy Carter\nD\n1976\n\n\n\n\n\n\n\n1980 Table\n\n\nCode\ndf_1980 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1980\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1980\n\n#create the dataframe using append and concat\ndf_1980.append(dataframe)\ndf_1980 = pd.concat(df_1980, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1980[\"State\"] = df_1980[0]\ndf_1980[\"Total Votes\"] = df_1980[1]\ndf_1980[\"Republican Votes\"] = df_1980[2]\ndf_1980[\"Republican Percentage\"] = df_1980[3]\ndf_1980[\"Republican Electoral\"] = df_1980[4]\ndf_1980[\"Democratic Votes\"] = df_1980[5]\ndf_1980[\"Democratic Percentage\"] = df_1980[6]\ndf_1980[\"Democratic Electoral\"] = df_1980[7]\ndf_1980[\"President Elect\"] = str(\"Ronald Reagan\")\ndf_1980[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_1980 = df_1980[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 8 rows of the data\ndf_1980 = df_1980.iloc[9:].reset_index(drop = True)\n#Drop every row below 50\ndf_1980 = df_1980.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_1980.head(), df_1980.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/1018073522.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1341929\n654192\n48.8\n9\n636730\n47.4\nNaN\nRonald Reagan\nR\n1980\n\n\n1\nAlaska\n158445\n86112\n54.3\n3\n41842\n26.4\nNaN\nRonald Reagan\nR\n1980\n\n\n2\nArizona\n873945\n529688\n60.6\n6\n246843\n28.2\nNaN\nRonald Reagan\nR\n1980\n\n\n3\nArkansas\n837582\n403164\n48.1\n6\n398041\n47.5\nNaN\nRonald Reagan\nR\n1980\n\n\n4\nCalifornia\n8587063\n4524858\n52.7\n45\n3083661\n35.9\nNaN\nRonald Reagan\nR\n1980\n\n\n46\nVirginia\n1866032\n989609\n53.0\n12\n752174\n40.3\nNaN\nRonald Reagan\nR\n1980\n\n\n47\nWashington\n1742394\n865244\n49.7\n9\n650193\n37.3\nNaN\nRonald Reagan\nR\n1980\n\n\n48\nWest Virginia\n737715\n334206\n45.3\nNaN\n367462\n49.8\n6\nRonald Reagan\nR\n1980\n\n\n49\nWisconsin\n2273221\n1088845\n47.9\n11\n981584\n43.2\nNaN\nRonald Reagan\nR\n1980\n\n\n50\nWyoming\n176713\n110700\n62.6\n3\n49427\n28.0\nNaN\nRonald Reagan\nR\n1980\n\n\n\n\n\n\n\n1984 Table\n\n\nCode\ndf_1984 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1984\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1984\n\n#create the dataframe using append and concat\ndf_1984.append(dataframe)\ndf_1984 = pd.concat(df_1984, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1984[\"State\"] = df_1984[0]\ndf_1984[\"Total Votes\"] = df_1984[1]\ndf_1984[\"Republican Votes\"] = df_1984[2]\ndf_1984[\"Republican Percentage\"] = df_1984[3]\ndf_1984[\"Republican Electoral\"] = df_1984[4]\ndf_1984[\"Democratic Votes\"] = df_1984[5]\ndf_1984[\"Democratic Percentage\"] = df_1984[6]\ndf_1984[\"Democratic Electoral\"] = df_1984[7]\ndf_1984[\"President Elect\"] = str(\"Ronald Reagan\")\ndf_1984[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_1984 = df_1984[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 9 rows of the data\ndf_1984 = df_1984.iloc[10:].reset_index(drop = True)\n#Drop every row below 50\ndf_1984 = df_1984.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data\npd.concat([df_1984.head(), df_1984.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/4035072081.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1441713\n872849\n60.5\n9\n551899\n38.3\nNaN\nRonald Reagan\nR\n1984\n\n\n1\nAlaska\n207605\n138377\n66.7\n3\n62007\n29.9\nNaN\nRonald Reagan\nR\n1984\n\n\n2\nArizona\n1025897\n681416\n66.4\n7\n333854\n32.5\nNaN\nRonald Reagan\nR\n1984\n\n\n3\nArkansas\n884406\n534774\n60.5\n6\n338646\n38.3\nNaN\nRonald Reagan\nR\n1984\n\n\n4\nCalifornia\n9505423\n5467009\n57.5\n47\n3922519\n41.3\nNaN\nRonald Reagan\nR\n1984\n\n\n46\nVirginia\n2146635\n1337078\n62.3\n12\n796250\n37.1\nNaN\nRonald Reagan\nR\n1984\n\n\n47\nWashington\n1883910\n1051670\n55.8\n10\n807352\n42.9\nNaN\nRonald Reagan\nR\n1984\n\n\n48\nWest Virginia\n735742\n405483\n55.1\n6\n328125\n44.6\nNaN\nRonald Reagan\nR\n1984\n\n\n49\nWisconsin\n2211689\n1198584\n54.2\n11\n995740\n45.0\nNaN\nRonald Reagan\nR\n1984\n\n\n50\nWyoming\n188968\n133241\n70.5\n3\n53370\n28.2\nNaN\nRonald Reagan\nR\n1984\n\n\n\n\n\n\n\n1988 Table\n\n\nCode\ndf_1988 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1988\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1988\n\n#create the dataframe using append and concat\ndf_1988.append(dataframe)\ndf_1988 = pd.concat(df_1988, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1988[\"State\"] = df_1988[0]\ndf_1988[\"Total Votes\"] = df_1988[1]\ndf_1988[\"Republican Votes\"] = df_1988[2]\ndf_1988[\"Republican Percentage\"] = df_1988[3]\ndf_1988[\"Republican Electoral\"] = df_1988[4]\ndf_1988[\"Democratic Votes\"] = df_1988[5]\ndf_1988[\"Democratic Percentage\"] = df_1988[6]\ndf_1988[\"Democratic Electoral\"] = df_1988[7]\ndf_1988[\"President Elect\"] = str(\"George H. W. Bush\")\ndf_1988[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_1988 = df_1988[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 9 rows of the data\ndf_1988 = df_1988.iloc[10:].reset_index(drop = True)\n#Drop every row below 50\ndf_1988 = df_1988.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_1988.head(), df_1988.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/1409139446.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1378476\n815576\n59.2\n9\n549506\n39.9\nNaN\nGeorge H. W. Bush\nR\n1988\n\n\n1\nAlaska\n200116\n119251\n59.6\n3\n72584\n36.3\nNaN\nGeorge H. W. Bush\nR\n1988\n\n\n2\nArizona\n1171873\n702541\n60.0\n7\n454029\n38.7\nNaN\nGeorge H. W. Bush\nR\n1988\n\n\n3\nArkansas\n827738\n466578\n56.4\n6\n349237\n42.2\nNaN\nGeorge H. W. Bush\nR\n1988\n\n\n4\nCalifornia\n9887065\n5054917\n51.1\n47\n4702233\n47.6\nNaN\nGeorge H. W. Bush\nR\n1988\n\n\n46\nVirginia\n2191609\n1309162\n59.7\n12\n859799\n39.2\nNaN\nGeorge H. W. Bush\nR\n1988\n\n\n47\nWashington\n1865253\n903835\n48.5\nNaN\n933516\n50.0\n10\nGeorge H. W. Bush\nR\n1988\n\n\n48\nWest Virginia*\n653311\n310065\n47.5\nNaN\n341016\n52.2\n5*\nGeorge H. W. Bush\nR\n1988\n\n\n49\nWisconsin\n2191608\n1047499\n47.8\nNaN\n1126794\n51.4\n11\nGeorge H. W. Bush\nR\n1988\n\n\n50\nWyoming\n176551\n106867\n60.5\n3\n67113\n38.0\nNaN\nGeorge H. W. Bush\nR\n1988\n\n\n\n\n\n\n\n1992 Table\n\n\nCode\ndf_1992 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1992\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1992\n\n#create the dataframe using append and concat\ndf_1992.append(dataframe)\ndf_1992 = pd.concat(df_1992, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1992[\"State\"] = df_1992[0]\ndf_1992[\"Total Votes\"] = df_1992[1]\ndf_1992[\"Republican Votes\"] = df_1992[5]\ndf_1992[\"Republican Percentage\"] = df_1992[6]\ndf_1992[\"Republican Electoral\"] = df_1992[7]\ndf_1992[\"Democratic Votes\"] = df_1992[2]\ndf_1992[\"Democratic Percentage\"] = df_1992[3]\ndf_1992[\"Democratic Electoral\"] = df_1992[4]\ndf_1992[\"President Elect\"] = str(\"Bill Clinton\")\ndf_1992[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_1992 = df_1992[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 9 rows of the data\ndf_1992 = df_1992.iloc[9:].reset_index(drop = True)\n#Drop every row below 50\ndf_1992 = df_1992.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_1992.head(), df_1992.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/1433862884.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1688060\n804283\n47.6\n9\n690080\n40.9\nNaN\nBill Clinton\nD\n1992\n\n\n1\nAlaska\n258506\n102000\n39.5\n3\n78294\n30.3\nNaN\nBill Clinton\nD\n1992\n\n\n2\nArizona\n1486975\n572086\n38.5\n8\n543050\n36.5\nNaN\nBill Clinton\nD\n1992\n\n\n3\nArkansas\n950653\n337324\n35.5\nNaN\n505823\n53.2\n6\nBill Clinton\nD\n1992\n\n\n4\nCalifornia\n11131721\n3630574\n32.6\nNaN\n5121325\n46.0\n54\nBill Clinton\nD\n1992\n\n\n46\nVirginia\n2558665\n1150517\n45.0\n13\n1038650\n40.6\nNaN\nBill Clinton\nD\n1992\n\n\n47\nWashington\n2288230\n731234\n32.0\nNaN\n993037\n43.4\n11\nBill Clinton\nD\n1992\n\n\n48\nWest Virginia\n683762\n241974\n35.4\nNaN\n331001\n48.4\n5\nBill Clinton\nD\n1992\n\n\n49\nWisconsin\n2531114\n930855\n36.8\nNaN\n1041066\n41.1\n11\nBill Clinton\nD\n1992\n\n\n50\nWyoming\n200598\n79347\n39.6\n3\n68160\n34.0\nNaN\nBill Clinton\nD\n1992\n\n\n\n\n\n\n\n1996 Table\n\n\nCode\ndf_1996 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/1996\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 1996\n\n#create the dataframe using append and concat\ndf_1996.append(dataframe)\ndf_1996 = pd.concat(df_1996, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_1996[\"State\"] = df_1996[0]\ndf_1996[\"Total Votes\"] = df_1996[1]\ndf_1996[\"Republican Votes\"] = df_1996[5]\ndf_1996[\"Republican Percentage\"] = df_1996[6]\ndf_1996[\"Republican Electoral\"] = df_1996[7]\ndf_1996[\"Democratic Votes\"] = df_1996[2]\ndf_1996[\"Democratic Percentage\"] = df_1996[3]\ndf_1996[\"Democratic Electoral\"] = df_1996[4]\ndf_1996[\"President Elect\"] = str(\"Bill Clinton\")\ndf_1996[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_1996 = df_1996[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 8 rows of the data\ndf_1996 = df_1996.iloc[9:].reset_index(drop = True)\n#Drop every row below 48\ndf_1996 = df_1996.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_1996.head(), df_1996.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/2163538421.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1534349\n769044\n50.1\n9\n662165\n43.2\nNaN\nBill Clinton\nD\n1996\n\n\n1\nAlaska\n241620\n122746\n50.8\n3\n80380\n33.3\nNaN\nBill Clinton\nD\n1996\n\n\n2\nArizona\n1404405\n622073\n44.3\nNaN\n653288\n46.5\n8\nBill Clinton\nD\n1996\n\n\n3\nArkansas\n884262\n325416\n36.8\nNaN\n475171\n53.7\n6\nBill Clinton\nD\n1996\n\n\n4\nCalifornia\n10019484\n3828380\n38.2\nNaN\n5119835\n51.1\n54\nBill Clinton\nD\n1996\n\n\n46\nVirginia\n2416642\n1138350\n47.1\n13\n1091060\n45.1\nNaN\nBill Clinton\nD\n1996\n\n\n47\nWashington\n2253837\n840712\n37.3\nNaN\n1123323\n49.8\n11\nBill Clinton\nD\n1996\n\n\n48\nWest Virginia\n636459\n233946\n36.8\nNaN\n327812\n51.5\n5\nBill Clinton\nD\n1996\n\n\n49\nWisconsin\n2196169\n845029\n38.5\nNaN\n1071971\n48.8\n11\nBill Clinton\nD\n1996\n\n\n50\nWyoming\n211571\n105388\n49.8\n3\n77934\n36.8\nNaN\nBill Clinton\nD\n1996\n\n\n\n\n\n\n\n2020 Table\n\n\nCode\ndf_2000 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/2000\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 2000\n\n#create the dataframe using append and concat\ndf_2000.append(dataframe)\ndf_2000 = pd.concat(df_2000, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_2000[\"State\"] = df_2000[0]\ndf_2000[\"Total Votes\"] = df_2000[1]\ndf_2000[\"Republican Votes\"] = df_2000[2]\ndf_2000[\"Republican Percentage\"] = df_2000[3]\ndf_2000[\"Republican Electoral\"] = df_2000[4]\ndf_2000[\"Democratic Votes\"] = df_2000[5]\ndf_2000[\"Democratic Percentage\"] = df_2000[6]\ndf_2000[\"Democratic Electoral\"] = df_2000[7]\ndf_2000[\"President Elect\"] = str(\"George W. Bush\")\ndf_2000[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_2000 = df_2000[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 8 rows of the data\ndf_2000 = df_2000.iloc[9:].reset_index(drop = True)\n#Drop every row below 50\ndf_2000 = df_2000.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data\npd.concat([df_2000.head(), df_2000.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/1121535106.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1666272\n941173\n56.5\n9\n692611\n41.6\nNaN\nGeorge W. Bush\nR\n2000\n\n\n1\nAlaska\n285560\n167398\n58.6\n3\n79004\n27.7\nNaN\nGeorge W. Bush\nR\n2000\n\n\n2\nArizona\n1532016\n781652\n51.0\n8\n685341\n44.7\nNaN\nGeorge W. Bush\nR\n2000\n\n\n3\nArkansas\n921781\n472940\n51.3\n6\n422768\n45.9\nNaN\nGeorge W. Bush\nR\n2000\n\n\n4\nCalifornia\n10965856\n4567429\n41.7\nNaN\n5861203\n53.4\n54\nGeorge W. Bush\nR\n2000\n\n\n46\nVirginia\n2739447\n1437490\n52.5\n13\n1217290\n44.4\nNaN\nGeorge W. Bush\nR\n2000\n\n\n47\nWashington\n2487433\n1108864\n44.6\nNaN\n1247652\n50.2\n11\nGeorge W. Bush\nR\n2000\n\n\n48\nWest Virginia\n648124\n336475\n51.9\n5\n295497\n45.6\nNaN\nGeorge W. Bush\nR\n2000\n\n\n49\nWisconsin\n2598607\n1237279\n47.6\nNaN\n1242987\n47.8\n11\nGeorge W. Bush\nR\n2000\n\n\n50\nWyoming\n218351\n147947\n67.8\n3\n60481\n27.7\nNaN\nGeorge W. Bush\nR\n2000\n\n\n\n\n\n\n\n2004 Table\n\n\nCode\ndf_2004 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/2004\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 2004\n\n#create the dataframe using append and concat\ndf_2004.append(dataframe)\ndf_2004 = pd.concat(df_2004, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_2004[\"State\"] = df_2004[0]\ndf_2004[\"Total Votes\"] = df_2004[1]\ndf_2004[\"Republican Votes\"] = df_2004[2]\ndf_2004[\"Republican Percentage\"] = df_2004[3]\ndf_2004[\"Republican Electoral\"] = df_2004[4]\ndf_2004[\"Democratic Votes\"] = df_2004[5]\ndf_2004[\"Democratic Percentage\"] = df_2004[6]\ndf_2004[\"Democratic Electoral\"] = df_2004[7]\ndf_2004[\"President Elect\"] = str(\"George W. Bush\")\ndf_2004[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_2004 = df_2004[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 8 rows of the data\ndf_2004 = df_2004.iloc[9:].reset_index(drop = True)\n#Drop every row below 48\ndf_2004 = df_2004.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data to ensure that the table looks correct\npd.concat([df_2004.head(), df_2004.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/2570025840.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n1883449\n1176394\n62.5\n9\n693933\n36.8\nNaN\nGeorge W. Bush\nR\n2004\n\n\n1\nAlaska\n312598\n190889\n61.1\n3\n111025\n35.5\nNaN\nGeorge W. Bush\nR\n2004\n\n\n2\nArizona\n2012585\n1104294\n54.9\n10\n893524\n44.4\nNaN\nGeorge W. Bush\nR\n2004\n\n\n3\nArkansas\n1054945\n572898\n54.3\n6\n469953\n44.5\nNaN\nGeorge W. Bush\nR\n2004\n\n\n4\nCalifornia\n12421852\n5509826\n44.4\nNaN\n6745485\n54.3\n55\nGeorge W. Bush\nR\n2004\n\n\n46\nVirginia\n3198367\n1716959\n53.7\n13\n1454742\n45.5\nNaN\nGeorge W. Bush\nR\n2004\n\n\n47\nWashington\n2859084\n1304894\n45.6\nNaN\n1510201\n52.8\n11\nGeorge W. Bush\nR\n2004\n\n\n48\nWest Virginia\n755887\n423778\n56.1\n5\n326541\n43.2\nNaN\nGeorge W. Bush\nR\n2004\n\n\n49\nWisconsin\n2997007\n1478120\n49.3\nNaN\n1489504\n49.7\n10\nGeorge W. Bush\nR\n2004\n\n\n50\nWyoming\n243428\n167629\n68.9\n3\n70776\n29.1\nNaN\nGeorge W. Bush\nR\n2004\n\n\n\n\n\n\n\n2008 Table\n\n\nCode\ndf_2008 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/2008\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 2008\n\n#create the dataframe using append and concat\ndf_2008.append(dataframe)\ndf_2008 = pd.concat(df_2008, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_2008[\"State\"] = df_2008[0]\ndf_2008[\"Total Votes\"] = df_2008[1]\ndf_2008[\"Republican Votes\"] = df_2008[5]\ndf_2008[\"Republican Percentage\"] = df_2008[6]\ndf_2008[\"Republican Electoral\"] = df_2008[7]\ndf_2008[\"Democratic Votes\"] = df_2008[2]\ndf_2008[\"Democratic Percentage\"] = df_2008[3]\ndf_2008[\"Democratic Electoral\"] = df_2008[4]\ndf_2008[\"President Elect\"] = str(\"Barack Obama\")\ndf_2008[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_2008 = df_2008[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \"Winning Party\", \"year\"]]\n\n#Drop the first 10 rows of the data\ndf_2008 = df_2008.iloc[9:].reset_index(drop = True)\n#Drop every row below 48\ndf_2008 = df_2008.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data\npd.concat([df_2008.head(), df_2008.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/3463852148.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n2099819\n1266546\n60.3%\n9\n813479\n38.7%\nNaN\nBarack Obama\nD\n2008\n\n\n1\nAlaska\n326197\n193841\n59.4%\n3\n123594\n37.9%\nNaN\nBarack Obama\nD\n2008\n\n\n2\nArizona\n2293475\n1230111\n53.6%\n10\n1034707\n45.1%\nNaN\nBarack Obama\nD\n2008\n\n\n3\nArkansas\n1086617\n638017\n58.7%\n6\n422310\n38.9%\nNaN\nBarack Obama\nD\n2008\n\n\n4\nCalifornia\n13561900\n5011781\n37.0%\nNaN\n8274473\n61.0%\n55\nBarack Obama\nD\n2008\n\n\n46\nVirginia\n3723260\n1725005\n46.3%\nNaN\n1959532\n52.6%\n13\nBarack Obama\nD\n2008\n\n\n47\nWashington\n3036878\n1229216\n40.5%\nNaN\n1750848\n57.7%\n11\nBarack Obama\nD\n2008\n\n\n48\nWest Virginia\n713362\n397466\n55.7%\n5\n303857\n42.6%\nNaN\nBarack Obama\nD\n2008\n\n\n49\nWisconsin\n2983417\n1262393\n42.3%\nNaN\n1677211\n56.2%\n10\nBarack Obama\nD\n2008\n\n\n50\nWyoming\n256035\n164958\n64.4%\n3\n82868\n32.4%\nNaN\nBarack Obama\nD\n2008\n\n\n\n\n\n\n\n2012 Table\n\n\nCode\ndf_2012 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/2012\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 2012\n\n#create the dataframe using append and concat\ndf_2012.append(dataframe)\ndf_2012 = pd.concat(df_2012, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_2012[\"State\"] = df_2012[0]\ndf_2012[\"Total Votes\"] = df_2012[1]\ndf_2012[\"Republican Votes\"] = df_2012[5]\ndf_2012[\"Republican Percentage\"] = df_2012[6]\ndf_2012[\"Republican Electoral\"] = df_2012[7]\ndf_2012[\"Democratic Votes\"] = df_2012[2]\ndf_2012[\"Democratic Percentage\"] = df_2012[3]\ndf_2012[\"Democratic Electoral\"] = df_2012[4]\ndf_2012[\"President Elect\"] = str(\"Barack Obama\")\ndf_2012[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_2012 = df_2012[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \n                  \"Winning Party\", \"year\"]]\n\n#Drop the first 10 rows of the data\ndf_2012 = df_2012.iloc[11:].reset_index(drop = True)\n#Drop every row below 50\ndf_2012 = df_2012.iloc[:51].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_2012.head(), df_2012.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/4149678721.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n2074338\n1255925\n60.5%\n9\n795696\n38.4%\nNaN\nBarack Obama\nD\n2012\n\n\n1\nAlaska\n300495\n164676\n54.8%\n3\n122640\n40.8%\nNaN\nBarack Obama\nD\n2012\n\n\n2\nArizona\n2299254\n1233654\n53.7%\n11\n1025232\n44.6%\nNaN\nBarack Obama\nD\n2012\n\n\n3\nArkansas\n1069468\n647744\n60.6%\n6\n394409\n36.9%\nNaN\nBarack Obama\nD\n2012\n\n\n4\nCalifornia\n13038547\n4839958\n37.1%\nNaN\n7854285\n60.2%\n55\nBarack Obama\nD\n2012\n\n\n46\nVirginia\n3854490\n1822522\n47.3%\nNaN\n1971820\n51.2%\n13\nBarack Obama\nD\n2012\n\n\n47\nWashington\n3125516\n1290670\n41.3%\nNaN\n1755396\n56.2%\n12\nBarack Obama\nD\n2012\n\n\n48\nWest Virginia\n670438\n417655\n62.3%\n5\n238269\n35.5%\nNaN\nBarack Obama\nD\n2012\n\n\n49\nWisconsin\n3071434\n1410966\n46.0%\nNaN\n1620985\n52.9%\n10\nBarack Obama\nD\n2012\n\n\n50\nWyoming\n249061\n170962\n68.6%\n3\n69286\n27.8%\nNaN\nBarack Obama\nD\n2012\n\n\n\n\n\n\n\n2016 Table\n\n\nCode\ndf_2016 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/2016\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 2016\n\n#create the dataframe using append and concat\ndf_2016.append(dataframe)\ndf_2016 = pd.concat(df_2016, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_2016[\"State\"] = df_2016[0]\ndf_2016[\"Total Votes\"] = df_2016[1]\ndf_2016[\"Republican Votes\"] = df_2016[5]\ndf_2016[\"Republican Percentage\"] = df_2016[6]\ndf_2016[\"Republican Electoral\"] = df_2016[7]\ndf_2016[\"Democratic Votes\"] = df_2016[2]\ndf_2016[\"Democratic Percentage\"] = df_2016[3]\ndf_2016[\"Democratic Electoral\"] = df_2016[4]\ndf_2016[\"President Elect\"] = str(\"Donald Trump\")\ndf_2016[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_2016 = df_2016[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \n                  \"Winning Party\", \"year\"]]\n\n#Drop the first 13 rows of the data\ndf_2016 = df_2016.iloc[14:].reset_index(drop = True)\n#Drop every row below 53\ndf_2016 = df_2016.iloc[:54].reset_index(drop = True)\n\n#Check top and bottom of data\npd.concat([df_2016.head(), df_2016.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/2658665327.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n2123372\n1318255\n62.1%\n9\n729547\n34.4%\nNaN\nDonald Trump\nR\n2016\n\n\n1\nAlaska\n318608\n163387\n51.3%\n3\n116454\n36.6%\nNaN\nDonald Trump\nR\n2016\n\n\n2\nArizona\n2573165\n1252401\n48.7%\n11\n1161167\n45.1%\nNaN\nDonald Trump\nR\n2016\n\n\n3\nArkansas\n1130635\n684872\n60.6%\n6\n380494\n33.7%\nNaN\nDonald Trump\nR\n2016\n\n\n4\nCalifornia\n14181595\n4483810\n31.6%\nNaN\n8753788\n61.7%\n55\nDonald Trump\nR\n2016\n\n\n49\nVirginia\n3982752\n1769443\n44.4%\nNaN\n1981473\n49.8%\n13\nDonald Trump\nR\n2016\n\n\n50\nWashington\n3209214\n1221747\n38.1%\nNaN\n1742718\n54.3%\n12\nDonald Trump\nR\n2016\n\n\n51\nWest Virginia\n713051\n489371\n68.6%\n5\n188794\n26.5%\nNaN\nDonald Trump\nR\n2016\n\n\n52\nWisconsin\n2976150\n1405284\n47.2%\n10\n1382536\n46.5%\nNaN\nDonald Trump\nR\n2016\n\n\n53\nWyoming\n255849\n174419\n68.2%\n3\n55973\n21.9%\nNaN\nDonald Trump\nR\n2016\n\n\n\n\n\n\n\n2020 Table\n\n\nCode\ndf_2020 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/2020\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 2020\n\n#create the dataframe using append and concat\ndf_2020.append(dataframe)\ndf_2020 = pd.concat(df_2020, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_2020[\"State\"] = df_2020[0]\ndf_2020[\"Total Votes\"] = df_2020[1]\ndf_2020[\"Republican Votes\"] = df_2020[5]\ndf_2020[\"Republican Percentage\"] = df_2020[6]\ndf_2020[\"Republican Electoral\"] = df_2020[7]\ndf_2020[\"Democratic Votes\"] = df_2020[2]\ndf_2020[\"Democratic Percentage\"] = df_2020[3]\ndf_2020[\"Democratic Electoral\"] = df_2020[4]\ndf_2020[\"President Elect\"] = str(\"Joe Biden\")\ndf_2020[\"Winning Party\"] = str(\"D\")\n\n#Remove all duplicate columns\ndf_2020 = df_2020[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \n                  \"Winning Party\", \"year\"]]\n\n#Drop the first 12 rows of the data\ndf_2020 = df_2020.iloc[13:].reset_index(drop = True)\n#Drop every row below 55\ndf_2020 = df_2020.iloc[:56].reset_index(drop = True)\n\n#Check top and bottom of data\npd.concat([df_2020.head(), df_2020.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/621203443.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n2323282\n1441170\n62.03%\n9\n849624\n36.57%\nNaN\nJoe Biden\nD\n2020\n\n\n1\nAlaska\n359530\n189951\n52.83%\n3\n153778\n42.77%\nNaN\nJoe Biden\nD\n2020\n\n\n2\nArizona\n3387326\n1661686\n49.06%\nNaN\n1672143\n49.36%\n11\nJoe Biden\nD\n2020\n\n\n3\nArkansas\n1219069\n760647\n62.40%\n6\n423932\n34.78%\nNaN\nJoe Biden\nD\n2020\n\n\n4\nCalifornia\n17500881\n6006429\n34.32%\nNaN\n11110250\n63.48%\n55\nJoe Biden\nD\n2020\n\n\n51\nVirginia\n4460524\n1962430\n44.00%\nNaN\n2413568\n54.11%\n13\nJoe Biden\nD\n2020\n\n\n52\nWashington\n4087631\n1584651\n38.77%\nNaN\n2369612\n57.97%\n12\nJoe Biden\nD\n2020\n\n\n53\nWest Virginia\n794652\n545382\n68.63%\n5\n235984\n29.70%\nNaN\nJoe Biden\nD\n2020\n\n\n54\nWisconsin\n3298041\n1610184\n48.82%\nNaN\n1630866\n49.45%\n10\nJoe Biden\nD\n2020\n\n\n55\nWyoming\n276765\n193559\n69.94%\n3\n73491\n26.55%\nNaN\nJoe Biden\nD\n2020\n\n\n\n\n\n\n\n2024 Table\n\n\nCode\ndf_2024 = []\n\nurl = f\"https://www.presidency.ucsb.edu/statistics/elections/2024\"\n    #We use requests to get the URL\nwebpage = requests.get(url)\n    #We then use the beautifulsoup function to use an html parser to scan the dev text of the website\nsoup = BeautifulSoup(webpage.text, \"html.parser\")\n    #the .find  function will look through soup to find the word table. Since there is only one table in the dev text we don't need to worry\n    #about it the wrong table being tagged\ntable = soup.find(\"table\")\n\n    #We then use read_html from pandas to scrape the tagged section of the dev code. Str() converts the contents to string type. [0] returns a df\ndataframe = pd.read_html(str(table))[0]\n    #this adds year as a variable in the data frame\ndataframe[\"year\"] = 2024\n\n#create the dataframe using append and concat\ndf_2024.append(dataframe)\ndf_2024 = pd.concat(df_2024, ignore_index = True)\n\n#Rename columns to the correct varaible names and add president elect and party\ndf_2024[\"State\"] = df_2024[0]\ndf_2024[\"Total Votes\"] = df_2024[1]\ndf_2024[\"Republican Votes\"] = df_2024[5]\ndf_2024[\"Republican Percentage\"] = df_2024[6]\ndf_2024[\"Republican Electoral\"] = df_2024[7]\ndf_2024[\"Democratic Votes\"] = df_2024[2]\ndf_2024[\"Democratic Percentage\"] = df_2024[3]\ndf_2024[\"Democratic Electoral\"] = df_2024[4]\ndf_2024[\"President Elect\"] = str(\"Donald Trump\")\ndf_2024[\"Winning Party\"] = str(\"R\")\n\n#Remove all duplicate columns\ndf_2024 = df_2024[[\"State\", \"Total Votes\", \"Republican Votes\", \n                  \"Republican Percentage\", \"Republican Electoral\", \"Democratic Votes\",\n                  \"Democratic Percentage\", \"Democratic Electoral\", \"President Elect\", \n                  \"Winning Party\", \"year\"]]\n\n#Drop the first 12 rows of the data\ndf_2024 = df_2024.iloc[13:].reset_index(drop = True)\n#Drop every row below 55\ndf_2024 = df_2024.iloc[:56].reset_index(drop = True)\n\n#Check top and bottom of data \npd.concat([df_2024.head(), df_2024.tail()])\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/1513066674.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  dataframe = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\nState\nTotal Votes\nRepublican Votes\nRepublican Percentage\nRepublican Electoral\nDemocratic Votes\nDemocratic Percentage\nDemocratic Electoral\nPresident Elect\nWinning Party\nyear\n\n\n\n\n0\nAlabama\n2265090\n1462616\n64.57%\n9\n772412\n34.10%\nNaN\nDonald Trump\nR\n2024\n\n\n1\nAlaska\n338177\n184458\n54.54%\n3\n140026\n41.41%\nNaN\nDonald Trump\nR\n2024\n\n\n2\nArizona\n3390161\n1770242\n52.22%\n11\n1582860\n46.69%\nNaN\nDonald Trump\nR\n2024\n\n\n3\nArkansas\n1182676\n759241\n64.20%\n6\n396905\n33.56%\nNaN\nDonald Trump\nR\n2024\n\n\n4\nCalifornia\n15865475\n6081697\n38.33%\nNaN\n9276179\n58.47%\n54\nDonald Trump\nR\n2024\n\n\n51\nVirginia\n4505941\n2075085\n46.05%\nNaN\n2335395\n51.83%\n13\nDonald Trump\nR\n2024\n\n\n52\nWashington\n3924243\n1530923\n39.01%\nNaN\n2245849\n57.23%\n12\nDonald Trump\nR\n2024\n\n\n53\nWest Virginia\n762390\n533556\n69.98%\n4\n214309\n28.11%\nNaN\nDonald Trump\nR\n2024\n\n\n54\nWisconsin\n3415787\n1697626\n49.70%\n10\n1668229\n48.84%\nNaN\nDonald Trump\nR\n2024\n\n\n55\nWyoming\n269048\n192633\n71.60%\n3\n69527\n25.84%\nNaN\nDonald Trump\nR\n2024\n\n\n\n\n\n\n\nNow we combine all of our tables into one dataframe\n\n\nCode\n#we can add all data together by combining data frames and using concat to create one big dataframe\n\nelection_years = [df_1948, df_1952, df_1956, df_1960, df_1964, df_1968,\n           df_1972, df_1976, df_1980, df_1984, df_1988, df_1992,\n           df_1996, df_2000, df_2004, df_2008, df_2012, df_2016, df_2020, df_2024]\n\nelection_df = pd.concat(election_years, ignore_index = True)\n\n\n#We use fillna to relace missing values or -- with 0\nelection_df = election_df.fillna(0)\nelection_df = election_df.replace(\"--\", 0)\n\n#We use regex to strip all asterisks\nelection_df = election_df.replace(\"\\*\", \"\", regex=True)\n\n\n\n&lt;&gt;:15: SyntaxWarning: invalid escape sequence '\\*'\n&lt;&gt;:15: SyntaxWarning: invalid escape sequence '\\*'\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_83231/756120839.py:15: SyntaxWarning: invalid escape sequence '\\*'\n  election_df = election_df.replace(\"\\*\", \"\", regex=True)\n\n\n\n\nCode\n#We can now write this data to a .csv file\n\nelection_df.to_csv(\"../data/raw/election_data.csv\")"
  },
  {
    "objectID": "Package_Demo.html",
    "href": "Package_Demo.html",
    "title": "Demonstration of the Functions:",
    "section": "",
    "text": "/var/folders/60/p3sjh3zx3793rb8gcc5_7qn00000gn/T/ipykernel_58870/90618530.py:206: DtypeWarning: Columns (4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('economic_election_data.csv')\n\n\n\nwrangle_data\nThis function, wrangle_data, allows us to wrangle downloadable csvs about economic data. Here we plug in our unemployment rate dataset and it does all of the wrangling and formatting for us. Here are just the first five rows of what the data will look like afterwards.\n\n\nCode\nUNRATE = wrangle_data(\n    filepath='UNRATE.csv',\n    value_col='UNRATE'\n)\n\nUNRATE.head()\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\n\n\n\n\n0\nJanuary\n1948\n3.4\n\n\n1\nFebruary\n1948\n3.8\n\n\n2\nMarch\n1948\n4.0\n\n\n3\nApril\n1948\n3.9\n\n\n4\nMay\n1948\n3.5\n\n\n\n\n\n\n\n\n\nmerge_and_sort_data\nThe next function, merge_and_sort_data, combines all of the economic data that we gathered into one data set. Here you can see that all three of the data sets are combined together to make one dataset. There are a few missing values but those get taken care of in another function that we have.\n\n\nCode\ncombined_data = merge_and_sort_data(UNRATE, GDP, CPI)\ncombined_data.head()\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\nGDP\nCPI\n\n\n\n\n0\nJanuary\n1948\n3.4\n265.742\n23.68\n\n\n1\nFebruary\n1948\n3.8\nNaN\n23.67\n\n\n2\nMarch\n1948\n4.0\nNaN\n23.50\n\n\n3\nApril\n1948\n3.9\n272.567\n23.82\n\n\n4\nMay\n1948\n3.5\nNaN\n24.01\n\n\n\n\n\n\n\n\n\nget_presidents_html & add_presidents_to_data\nOur next fuction, get_presidents_html, allows us to scrape the data about presidents of the United States, the years that they were president and the political party that they represented. This allows for easier data combination and cleaning so we will combine that with the last function, add_presidnets_to_data, we combine the data that we have and clean it creating our final president and economic dataset ready to be combined with the election data.\n\n\nCode\nurl = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States' \nemail = \"skirk03@byu.edu\" \nua = f\"STAT386-class-scraper/1.0 (+{email})\" \nr = requests.get(url, headers={\"User-Agent\": ua, \"From\": email}, timeout=15)\n\ntext = get_presidents_html(ua = f\"STAT386-class-scraper/1.0 (+{email})\", email = \"skirk03@byu.edu\")\n\nFinal_df = add_presidents_to_data(combined_data, text)\nFinal_df.head(20)\n\n\n/var/folders/60/p3sjh3zx3793rb8gcc5_7qn00000gn/T/ipykernel_58870/90618530.py:52: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  tables = pd.read_html(html_text)\n/var/folders/60/p3sjh3zx3793rb8gcc5_7qn00000gn/T/ipykernel_58870/90618530.py:70: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  df[\"Start_Date\"] = pd.to_datetime(\n/var/folders/60/p3sjh3zx3793rb8gcc5_7qn00000gn/T/ipykernel_58870/90618530.py:73: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  df[\"End_Date\"] = pd.to_datetime(\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\nGDP\nCPI\nPresident\nParty\n\n\n\n\n0\nJanuary\n1948\n3.4\n265.742000\n23.68\nHarry S Truman\nDemocratic\n\n\n2\nFebruary\n1948\n3.8\n268.017000\n23.67\nHarry S Truman\nDemocratic\n\n\n4\nMarch\n1948\n4.0\n270.292000\n23.50\nHarry S Truman\nDemocratic\n\n\n6\nApril\n1948\n3.9\n272.567000\n23.82\nHarry S Truman\nDemocratic\n\n\n8\nMay\n1948\n3.5\n274.776667\n24.01\nHarry S Truman\nDemocratic\n\n\n10\nJune\n1948\n3.6\n276.986333\n24.15\nHarry S Truman\nDemocratic\n\n\n12\nJuly\n1948\n3.6\n279.196000\n24.40\nHarry S Truman\nDemocratic\n\n\n14\nAugust\n1948\n3.9\n279.586000\n24.43\nHarry S Truman\nDemocratic\n\n\n16\nSeptember\n1948\n3.8\n279.976000\n24.36\nHarry S Truman\nDemocratic\n\n\n18\nOctober\n1948\n3.7\n280.366000\n24.31\nHarry S Truman\nDemocratic\n\n\n20\nNovember\n1948\n3.8\n278.588667\n24.16\nHarry S Truman\nDemocratic\n\n\n22\nDecember\n1948\n4.0\n276.811333\n24.05\nHarry S Truman\nDemocratic\n\n\n24\nJanuary\n1949\n4.3\n275.034000\n24.01\nHarry S Truman\nDemocratic\n\n\n26\nFebruary\n1949\n4.7\n273.806333\n23.91\nHarry S Truman\nDemocratic\n\n\n28\nMarch\n1949\n5.0\n272.578667\n23.91\nHarry S Truman\nDemocratic\n\n\n30\nApril\n1949\n5.3\n271.351000\n23.92\nHarry S Truman\nDemocratic\n\n\n32\nMay\n1949\n6.1\n271.863667\n23.91\nHarry S Truman\nDemocratic\n\n\n34\nJune\n1949\n6.2\n272.376333\n23.92\nHarry S Truman\nDemocratic\n\n\n36\nJuly\n1949\n6.7\n272.889000\n23.70\nHarry S Truman\nDemocratic\n\n\n38\nAugust\n1949\n6.8\n272.135000\n23.70\nHarry S Truman\nDemocratic\n\n\n\n\n\n\n\n\n\nsimple_eda\nAnother function we have allows for some basic eda and creates a correlation matrix for the factors that are used in our dataset and how they influence each other.\n\n\nCode\nsimple_eda(df, election_years_only=False)\n\n\n{'regression_data':            CPI  UNRATE           GDP  Republican Percentage  \\\n 0       23.680     3.4    265.742000                  19.00   \n 1       23.680     3.4    265.742000                  43.80   \n 2       23.680     3.4    265.742000                  21.00   \n 3       23.680     3.4    265.742000                  47.10   \n 4       23.680     3.4    265.742000                  46.50   \n ...        ...     ...           ...                    ...   \n 47699  317.603     4.1  29969.802667                  46.05   \n 47700  317.603     4.1  29969.802667                  39.01   \n 47701  317.603     4.1  29969.802667                  69.98   \n 47702  317.603     4.1  29969.802667                  49.70   \n 47703  317.603     4.1  29969.802667                  71.60   \n \n        Democratic Percentage  \n 0                       0.00  \n 1                      53.80  \n 2                      61.70  \n 3                      47.60  \n 4                      51.90  \n ...                      ...  \n 47699                  51.83  \n 47700                  57.23  \n 47701                  28.11  \n 47702                  48.84  \n 47703                  25.84  \n \n [12276 rows x 5 columns],\n 'correlation_matrix':                        Total Votes  Republican Votes  Republican Percentage  \\\n Total Votes               1.000000          0.969986              -0.081917   \n Republican Votes          0.969986          1.000000               0.053214   \n Republican Percentage    -0.081917          0.053214               1.000000   \n Republican Electoral      0.437137          0.585495               0.355254   \n Democratic Votes          0.980228          0.911472              -0.162722   \n Democratic Percentage     0.147370          0.047304              -0.740895   \n Democratic Electoral      0.582448          0.421036              -0.408526   \n UNRATE                    0.080245          0.076761               0.007525   \n GDP                       0.236310          0.228975              -0.008160   \n CPI                       0.244334          0.232681              -0.024641   \n Year                      0.245630          0.234175              -0.014445   \n Election Cycle            0.245630          0.234175              -0.014445   \n \n                        Republican Electoral  Democratic Votes  \\\n Total Votes                        0.437137          0.980228   \n Republican Votes                   0.585495          0.911472   \n Republican Percentage              0.355254         -0.162722   \n Republican Electoral               1.000000          0.298537   \n Democratic Votes                   0.298537          1.000000   \n Democratic Percentage             -0.291936          0.246491   \n Democratic Electoral              -0.382130          0.681338   \n UNRATE                            -0.021282          0.075143   \n GDP                               -0.092791          0.244251   \n CPI                               -0.095640          0.249520   \n Year                              -0.086234          0.246665   \n Election Cycle                    -0.086234          0.246665   \n \n                        Democratic Percentage  Democratic Electoral    UNRATE  \\\n Total Votes                         0.147370              0.582448  0.080245   \n Republican Votes                    0.047304              0.421036  0.076761   \n Republican Percentage              -0.740895             -0.408526  0.007525   \n Republican Electoral               -0.291936             -0.382130 -0.021282   \n Democratic Votes                    0.246491              0.681338  0.075143   \n Democratic Percentage               1.000000              0.430514  0.002662   \n Democratic Electoral                0.430514              1.000000  0.020430   \n UNRATE                              0.002662              0.020430  1.000000   \n GDP                                 0.078712              0.060607  0.125352   \n CPI                                 0.069073              0.067373  0.214730   \n Year                                0.046464              0.058699  0.317797   \n Election Cycle                      0.046464              0.058699  0.317797   \n \n                             GDP       CPI      Year  Election Cycle  \n Total Votes            0.236310  0.244334  0.245630        0.245630  \n Republican Votes       0.228975  0.232681  0.234175        0.234175  \n Republican Percentage -0.008160 -0.024641 -0.014445       -0.014445  \n Republican Electoral  -0.092791 -0.095640 -0.086234       -0.086234  \n Democratic Votes       0.244251  0.249520  0.246665        0.246665  \n Democratic Percentage  0.078712  0.069073  0.046464        0.046464  \n Democratic Electoral   0.060607  0.067373  0.058699        0.058699  \n UNRATE                 0.125352  0.214730  0.317797        0.317797  \n GDP                    1.000000  0.975727  0.923433        0.923433  \n CPI                    0.975727  1.000000  0.974139        0.974139  \n Year                   0.923433  0.974139  1.000000        1.000000  \n Election Cycle         0.923433  0.974139  1.000000        1.000000  ,\n 'vote_cols': ['Republican Percentage', 'Democratic Percentage'],\n 'econ_cols': ['CPI', 'UNRATE', 'GDP']}\n\n\n\n\neconomic_trends_for_president\nThis econimic_trends_for_president function allows users to select a president of their choice and see the economic impact that took place during their presidency. There is an option to select just one of the specified economic evaluators or just two of them or even all three. Users can also filter based on the term that the president was serving in at the time.\n\n\nCode\neconomic_trends_for_president(df, \"Donald Trump\", indicators = None)\n\n\n\n\n\n\n\n\n\nYear\nMonth\nGDP\nCPI\nUNRATE\n\n\n\n\n41642\n2016\nJanuary\n18525.933000\n237.652\n4.8\n\n\n41696\n2016\nFebruary\n18587.856000\n237.336\n4.9\n\n\n41750\n2016\nMarch\n18649.779000\n238.080\n5.0\n\n\n41804\n2016\nApril\n18711.702000\n238.992\n5.1\n\n\n41858\n2016\nMay\n18772.014333\n239.557\n4.8\n\n\n...\n...\n...\n...\n...\n...\n\n\n47984\n2025\nMay\n30485.729000\n320.580\n4.2\n\n\n48040\n2025\nJune\n30485.729000\n321.500\n4.1\n\n\n48096\n2025\nJuly\n30485.729000\n322.132\n4.2\n\n\n48152\n2025\nAugust\n30485.729000\n323.364\n4.3\n\n\n48208\n2025\nSeptember\n30485.729000\n324.368\n4.4\n\n\n\n\n69 rows  5 columns\n\n\n\n\n\npresident_party_and_economic_analysis\nThe president_party_and_economic_analysis function allows a user to select a president and from there they will get an analysis on how every state voted in the next election. The final party of the analysis tells how the next election ended and whether or not the party in office switched.\n\n\nCode\npresident_party_and_economic_analyis(df, \"Barack Obama\")\n\n\n{'president': 'Barack Obama',\n 'overall_economic_changes': {'start_year': np.int64(2008),\n  'end_year': np.int64(2015),\n  'years_in_office': np.int64(8),\n  'GDP_change': np.float64(3558.265666666668),\n  'CPI_change': np.float64(23.555999999999983),\n  'UNRATE_change': np.float64(0.0)},\n 'last_year_changes': {'year': np.int64(2015),\n  'GDP_change': np.float64(144.1826666666675),\n  'CPI_change': np.float64(1.275999999999982),\n  'UNRATE_change': np.float64(-0.40000000000000036)},\n 'state_vote_swings': [{'State': 'Alabama',\n   'Republican_swing': 1.6000000000000014,\n   'Democratic_swing': -4.0},\n  {'State': 'Alaska',\n   'Republican_swing': -3.5,\n   'Democratic_swing': -4.199999999999996},\n  {'State': 'Arizona', 'Republican_swing': -5.0, 'Democratic_swing': 0.5},\n  {'State': 'Arkansas',\n   'Republican_swing': 0.0,\n   'Democratic_swing': -3.1999999999999957},\n  {'State': 'California', 'Republican_swing': -5.5, 'Democratic_swing': 1.5},\n  {'State': 'Colorado',\n   'Republican_swing': -2.8000000000000043,\n   'Democratic_swing': -3.299999999999997},\n  {'State': 'Connecticut',\n   'Republican_swing': 0.19999999999999574,\n   'Democratic_swing': -3.5},\n  {'State': 'Delaware',\n   'Republican_swing': 1.8999999999999986,\n   'Democratic_swing': -5.200000000000003},\n  {'State': 'Dist. of Col.',\n   'Republican_swing': -3.2,\n   'Democratic_swing': 0.0},\n  {'State': 'Florida',\n   'Republican_swing': -0.10000000000000142,\n   'Democratic_swing': -2.200000000000003},\n  {'State': 'Georgia',\n   'Republican_swing': -2.299999999999997,\n   'Democratic_swing': 0.3999999999999986},\n  {'State': 'Hawaii',\n   'Republican_swing': 2.1999999999999993,\n   'Democratic_swing': -8.299999999999997},\n  {'State': 'Idaho',\n   'Republican_swing': -5.200000000000003,\n   'Democratic_swing': -5.100000000000001},\n  {'State': 'Illinois',\n   'Republican_swing': -1.9000000000000057,\n   'Democratic_swing': -1.8000000000000043},\n  {'State': 'Indiana',\n   'Republican_swing': 2.799999999999997,\n   'Democratic_swing': -6.100000000000001},\n  {'State': 'Iowa',\n   'Republican_swing': 4.899999999999999,\n   'Democratic_swing': -10.299999999999997},\n  {'State': 'Kansas',\n   'Republican_swing': -3.0,\n   'Democratic_swing': -1.8999999999999986},\n  {'State': 'Kentucky',\n   'Republican_swing': 2.0,\n   'Democratic_swing': -5.099999999999994},\n  {'State': 'Louisiana',\n   'Republican_swing': 0.30000000000000426,\n   'Democratic_swing': -2.200000000000003},\n  {'State': 'Maine',\n   'Republican_swing': 3.8999999999999986,\n   'Democratic_swing': -8.5},\n  {'State': 'Maryland',\n   'Republican_swing': -2.0,\n   'Democratic_swing': -1.7000000000000028},\n  {'State': 'Massachusetts',\n   'Republican_swing': -4.700000000000003,\n   'Democratic_swing': -0.7000000000000028},\n  {'State': 'Michigan',\n   'Republican_swing': 2.799999999999997,\n   'Democratic_swing': -6.900000000000006},\n  {'State': 'Minnesota',\n   'Republican_swing': -0.10000000000000142,\n   'Democratic_swing': -6.300000000000004},\n  {'State': 'Mississippi',\n   'Republican_swing': 2.6000000000000014,\n   'Democratic_swing': -3.6999999999999957},\n  {'State': 'Missouri',\n   'Republican_swing': 3.0,\n   'Democratic_swing': -6.299999999999997},\n  {'State': 'Montana',\n   'Republican_swing': 1.1000000000000014,\n   'Democratic_swing': -5.800000000000004},\n  {'State': 'Nebraska',\n   'Republican_swing': -1.0999999999999943,\n   'Democratic_swing': -4.299999999999997},\n  {'State': 'Nevada',\n   'Republican_swing': -0.20000000000000284,\n   'Democratic_swing': -4.5},\n  {'State': 'New Hampshire',\n   'Republican_swing': 0.0,\n   'Democratic_swing': -5.200000000000003},\n  {'State': 'New Jersey',\n   'Republican_swing': 0.7999999999999972,\n   'Democratic_swing': -2.799999999999997},\n  {'State': 'New Mexico',\n   'Republican_swing': -2.799999999999997,\n   'Democratic_swing': -4.700000000000003},\n  {'State': 'New York',\n   'Republican_swing': 1.3999999999999986,\n   'Democratic_swing': -4.5},\n  {'State': 'North Carolina',\n   'Republican_swing': -0.6000000000000014,\n   'Democratic_swing': -2.1999999999999957},\n  {'State': 'North Dakota',\n   'Republican_swing': 4.700000000000003,\n   'Democratic_swing': -11.500000000000004},\n  {'State': 'Ohio',\n   'Republican_swing': 4.0,\n   'Democratic_swing': -7.100000000000001},\n  {'State': 'Oklahoma',\n   'Republican_swing': -1.5,\n   'Democratic_swing': -4.300000000000004},\n  {'State': 'Oregon',\n   'Republican_swing': -3.0,\n   'Democratic_swing': -4.100000000000001},\n  {'State': 'Pennsylvania',\n   'Republican_swing': 1.8999999999999986,\n   'Democratic_swing': -4.200000000000003},\n  {'State': 'Rhode Island',\n   'Republican_swing': 3.6999999999999957,\n   'Democratic_swing': -8.300000000000004},\n  {'State': 'South Carolina',\n   'Republican_swing': 0.29999999999999716,\n   'Democratic_swing': -3.3999999999999986},\n  {'State': 'South Dakota',\n   'Republican_swing': 3.6000000000000014,\n   'Democratic_swing': -8.2},\n  {'State': 'Tennessee',\n   'Republican_swing': 1.2000000000000028,\n   'Democratic_swing': -4.399999999999999},\n  {'State': 'Texas',\n   'Republican_swing': -5.0,\n   'Democratic_swing': 1.8000000000000043},\n  {'State': 'Utah',\n   'Republican_swing': -27.299999999999997,\n   'Democratic_swing': 2.8000000000000007},\n  {'State': 'Vermont',\n   'Republican_swing': -0.6999999999999993,\n   'Democratic_swing': -9.899999999999991},\n  {'State': 'Virginia',\n   'Republican_swing': -2.8999999999999986,\n   'Democratic_swing': -1.4000000000000057},\n  {'State': 'Washington',\n   'Republican_swing': -3.1999999999999957,\n   'Democratic_swing': -1.9000000000000057},\n  {'State': 'West Virginia',\n   'Republican_swing': 6.299999999999997,\n   'Democratic_swing': -9.0},\n  {'State': 'Wisconsin',\n   'Republican_swing': 1.2000000000000028,\n   'Democratic_swing': -6.399999999999999},\n  {'State': 'Wyoming',\n   'Republican_swing': -0.3999999999999915,\n   'Democratic_swing': -5.900000000000002}],\n 'party_transition': {'current_party': 'D',\n  'following_president': 'Donald Trump',\n  'next_party': 'R',\n  'party_switched': True}}"
  },
  {
    "objectID": "Final.html",
    "href": "Final.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nIntroduction:\nFor this project we were curious about what things impact elections. We gathered some election data as well as economic data and did some basic exploratory data analysis to come up with some interesting findings.\n\n\nData Collection:\nGetting our data was quite the process. We gathered data from a bunch of different sources and then combined them all together to make our dataset. We scraped some tables and that presented a few challenges especially with the election data that we have because each of the tables was formatted a little differently from each other, so we had to hard code the scraping for each table. There were also some parts of the data that we gathered that were simple csvs that just needed to be downloaded and wrangled. So after we gathered all of the data we wrangled them so that they could all be easily merged together. Ultimately we have created a data set that includes election data from 1948 onwards as well as the GDP, CPI and unemployment rates for every month from 1948 until now as well. We wanted to gather this data to see if we could do an interesting study on predictors for which political party would be elected.\n\n\nData Wrangling:\nThere was a lot of wrangling that we needed to do for this data set. There were three small downloadable csvs that we got and the wrangling for those mostly consisted of renaming columns, and calculating a few things to make new columns. The larger part of the wrangling came with the presidents and election portions of the dataset. Both of these had some missing data that needed to be filled in. We couldnt used a mean or median imputation for filling those values either as some of them were just unknown or were president names that didnt get scraped properly. In order to fix that we needed to be very specific in filling in those values. The thing that worked best was actually just to create some lists and then merge that with the data set in order to fill in those missing values. Then for the last part of the wrangling we had to make sure that the data had similar columns and formats so that we could merge them properly."
  },
  {
    "objectID": "scripts/Presidents.html",
    "href": "scripts/Presidents.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All Code\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom bs4 import BeautifulSoup\nimport re \n\n\ndf = pd.read_csv('../data/raw/UNRATE.csv')\ndf['Year'] = df['observation_date'].str.extract(r'(\\d{4})')\ndf['Month'] = df['observation_date'].str.extract(r'((?&lt;=\\d{4}-)\\d{2})')\n# df['Day'] = df['observation_date'].str.extract(r'((?&lt;=\\d{4}-\\d{2}-)\\d{2})')\ndf = df.drop('observation_date', axis = 1)\ndf['Month'] = df['Month'].astype(int)\ndf['Month'] = pd.to_datetime(df['Month'], format='%m').dt.month_name()\ndf['Year'] = df['Year'].astype(int)\ncolumn_order = ['Month', 'Year', 'UNRATE']\nUNRATE = df[column_order]\nUNRATE.head()\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\n\n\n\n\n0\nJanuary\n1948\n3.4\n\n\n1\nFebruary\n1948\n3.8\n\n\n2\nMarch\n1948\n4.0\n\n\n3\nApril\n1948\n3.9\n\n\n4\nMay\n1948\n3.5\n\n\n\n\n\n\n\n\n\nCode\ndf= pd.read_csv('../data/rawGDP.csv')\ndf = df.drop([0,1,2,3])\ndf['Year'] = df['observation_date'].str.extract(r'(\\d{4})')\ndf['Month'] = df['observation_date'].str.extract(r'((?&lt;=\\d{4}-)\\d{2})')\ndf = df.drop('observation_date', axis = 1)\ndf['Month'] = df['Month'].astype(int)\ndf['Month'] = pd.to_datetime(df['Month'], format='%m').dt.month_name()\ndf['Year'] = df['Year'].astype(int)\ncolumn_order = ['Month', 'Year', 'GDP']\nGDP = df[column_order]\nGDP.head()\n\n\n\n\n\n\n\n\n\nMonth\nYear\nGDP\n\n\n\n\n4\nJanuary\n1948\n265.742\n\n\n5\nApril\n1948\n272.567\n\n\n6\nJuly\n1948\n279.196\n\n\n7\nOctober\n1948\n280.366\n\n\n8\nJanuary\n1949\n275.034\n\n\n\n\n\n\n\n\n\nCode\ndf = pd.read_csv('../data/rawCPI.csv')\ndf = df.drop(df.index[0:12])\ndf['Year'] = df['observation_date'].str.extract(r'(\\d{4})')\ndf['Month'] = df['observation_date'].str.extract(r'((?&lt;=\\d{4}-)\\d{2})')\ndf['CPI'] = df['CPIAUCSL']\ndf = df.drop('observation_date', axis = 1)\ndf = df.drop('CPIAUCSL', axis = 1)\ndf['Month'] = df['Month'].astype(int)\ndf['Month'] = pd.to_datetime(df['Month'], format='%m').dt.month_name()\ndf['Year'] = df['Year'].astype(int)\ncolumn_order = ['Month', 'Year', 'CPI']\nCPI = df[column_order]\nCPI.head()\n\n\n\n\n\n\n\n\n\nMonth\nYear\nCPI\n\n\n\n\n12\nJanuary\n1948\n23.68\n\n\n13\nFebruary\n1948\n23.67\n\n\n14\nMarch\n1948\n23.50\n\n\n15\nApril\n1948\n23.82\n\n\n16\nMay\n1948\n24.01\n\n\n\n\n\n\n\n\n\nCode\ncombined = pd.merge(UNRATE, GDP, on=['Month', 'Year'], how='outer')\ncombined.head()\ndata = pd.merge(combined, CPI, on=['Year', 'Month'], how='outer') \nmonth_order = [\n    \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n    \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n]\ndata[\"Month\"] = pd.Categorical(data[\"Month\"], categories=month_order, ordered=True)\ndata = data.sort_values([\"Year\", \"Month\"]).reset_index(drop=True)\ndata.head(20)\n\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\nGDP\nCPI\n\n\n\n\n0\nJanuary\n1948\n3.4\n265.742\n23.68\n\n\n1\nFebruary\n1948\n3.8\nNaN\n23.67\n\n\n2\nMarch\n1948\n4.0\nNaN\n23.50\n\n\n3\nApril\n1948\n3.9\n272.567\n23.82\n\n\n4\nMay\n1948\n3.5\nNaN\n24.01\n\n\n5\nJune\n1948\n3.6\nNaN\n24.15\n\n\n6\nJuly\n1948\n3.6\n279.196\n24.40\n\n\n7\nAugust\n1948\n3.9\nNaN\n24.43\n\n\n8\nSeptember\n1948\n3.8\nNaN\n24.36\n\n\n9\nOctober\n1948\n3.7\n280.366\n24.31\n\n\n10\nNovember\n1948\n3.8\nNaN\n24.16\n\n\n11\nDecember\n1948\n4.0\nNaN\n24.05\n\n\n12\nJanuary\n1949\n4.3\n275.034\n24.01\n\n\n13\nFebruary\n1949\n4.7\nNaN\n23.91\n\n\n14\nMarch\n1949\n5.0\nNaN\n23.91\n\n\n15\nApril\n1949\n5.3\n271.351\n23.92\n\n\n16\nMay\n1949\n6.1\nNaN\n23.91\n\n\n17\nJune\n1949\n6.2\nNaN\n23.92\n\n\n18\nJuly\n1949\n6.7\n272.889\n23.70\n\n\n19\nAugust\n1949\n6.8\nNaN\n23.70\n\n\n\n\n\n\n\n\n\nCode\nimport requests \nimport re \nfrom bs4 import BeautifulSoup \nimport pandas as pd \nimport numpy as np       \nurl = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States' \nemail = \"skirk03@byu.edu\" \nua = f\"STAT386-class-scraper/1.0 (+{email})\" \nr = requests.get(url, headers={\"User-Agent\": ua, \"From\": email}, timeout=15)\n\n\n\n\nCode\nbs = BeautifulSoup(r.text, 'html.parser')\ntables = pd.read_html(r.text)\ndf = tables[0]\ndf.columns\ndf[\"No.\"] = df[\"No.[a]\"]\ndf['President'] = df['Name (birthdeath)'].str.extract(r'([A-Z][a-z]+\\W[A-Z][a-z]+)')\ndf['Party'] = df['Party[b][17].1']\ndf[['Start', 'End']] = df['Term[16]'].str.split('', expand=True)\ndf['Start_Month'] = df['Start'].str.extract(r'([A-Z][a-z]+)')\ndf['Start_Year'] = df['Start'].str.extract(r'(\\d{4})')\ndf['End_Month'] = df['End'].str.extract(r'([A-Z][a-z]+)')\ndf['End_Year'] = df['End'].str.extract(r'(\\d{4})')\n\n\ndf = df.drop('Portrait', axis = 1)\ndf = df.drop('Party[b][17]', axis = 1)\ndf = df.drop('Vice President[18]', axis = 1)\ndf = df.drop('No.[a]', axis = 1)\ndf = df.drop('Name (birthdeath)', axis = 1)\ndf = df.drop('Party[b][17].1', axis = 1)\ndf = df.drop('Term[16]', axis = 1)\ndf = df.drop('Start', axis = 1)\ndf = df.drop('End', axis = 1)\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_73166/1178456700.py:2: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  tables = pd.read_html(r.text)\n\n\n\n\nCode\ndf['End_Year'] = df['End_Year'].fillna(2025)\ndf.loc[df['End_Month'] == 'Incumbent', 'End_Month'] = 'November'\ndf.tail()\n\ndf['Start_Date'] = pd.to_datetime(df['Start_Month'] + \" \" + df['Start_Year'].astype(str))\ndf['End_Date'] = pd.to_datetime(df['End_Month'] + \" \" + df['End_Year'].astype(str))\n\nrows = []\n\nfor _, row in df.iterrows():\n    dates = pd.date_range(start=row['Start_Date'], end=row['End_Date'], freq='MS')\n    \n    for d in dates:\n        new_row = row.to_dict()          # keep ALL original columns\n        new_row['Year'] = d.year\n        new_row['Month'] = d.month_name()\n        new_row['Month_Num'] = d.month\n        rows.append(new_row)\n\nPresidents = pd.DataFrame(rows)\nPresidents = Presidents.drop('Month_Num', axis = 1)\nPresidents = Presidents.drop('Start_Month', axis = 1)\nPresidents = Presidents.drop('Start_Year', axis = 1)\nPresidents = Presidents.drop('End_Month', axis = 1)\nPresidents = Presidents.drop('End_Year', axis = 1)\nPresidents = Presidents.drop('Start_Date', axis = 1)\nPresidents = Presidents.drop('End_Date', axis = 1)\nPresidents = Presidents.drop('Election', axis = 1)\nPresidents = Presidents.drop('No.', axis = 1)\nPresidents = Presidents[Presidents['Year'] &gt;= 1948]\ncolumn_order = ['Month', 'Year', 'President', 'Party']\nPresidents = Presidents[column_order]\n\n\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_73166/1740070359.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  df['Start_Date'] = pd.to_datetime(df['Start_Month'] + \" \" + df['Start_Year'].astype(str))\n/var/folders/g0/nsxm0s0x64z69dg0l2b9mf4m0000gn/T/ipykernel_73166/1740070359.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  df['End_Date'] = pd.to_datetime(df['End_Month'] + \" \" + df['End_Year'].astype(str))\n\n\n\n\nCode\nFinal = pd.merge(data, Presidents, on=['Year', 'Month'], how='outer')\nFinal.head(500)\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\nGDP\nCPI\nPresident\nParty\n\n\n\n\n0\nApril\n1948\n3.9\n272.567\n23.82\nNaN\nDemocratic\n\n\n1\nApril\n1948\n3.9\n272.567\n23.82\nNaN\nDemocratic\n\n\n2\nAugust\n1948\n3.9\nNaN\n24.43\nNaN\nDemocratic\n\n\n3\nAugust\n1948\n3.9\nNaN\n24.43\nNaN\nDemocratic\n\n\n4\nDecember\n1948\n4.0\nNaN\n24.05\nNaN\nDemocratic\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n495\nJanuary\n1969\n3.4\n993.337\n35.70\nRichard Nixon\nRepublican\n\n\n496\nJanuary\n1969\n3.4\n993.337\n35.70\nRichard Nixon\nRepublican\n\n\n497\nJuly\n1969\n3.5\n1029.956\n36.80\nRichard Nixon\nRepublican\n\n\n498\nJuly\n1969\n3.5\n1029.956\n36.80\nRichard Nixon\nRepublican\n\n\n499\nJuly\n1969\n3.5\n1029.956\n36.80\nRichard Nixon\nRepublican\n\n\n\n\n500 rows  7 columns\n\n\n\n\n\nCode\nFinal[\"Month\"] = Final[\"Month\"].str.strip()\nFinal[\"President\"] = Final[\"President\"].str.strip()\n\n\nmonth_map = {\n    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4,\n    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8,\n    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12,\n}\n\n\nterms = [\n    (\"Harry S Truman\",  (1945, 'April'),  (1953, 'January')),\n    (\"Dwight D Eisenhower\", (1953, 'January'), (1961, 'January')),\n    (\"John F Kennedy\",  (1961, 'January'), (1963, 'November')),\n    (\"Lyndon B Johnson\", (1963, 'November'), (1969, 'January')),\n]\n\nfor i, row in Final.iterrows():\n    if pd.isna(row[\"President\"]):\n\n        current = (row[\"Year\"], month_map[row[\"Month\"]])\n\n        for pres, (sy, sm), (ey, em) in terms:\n            start = (sy, month_map[sm])\n            end   = (ey, month_map[em])\n\n            if start &lt;= current &lt; end:\n                Final.loc[i, \"President\"] = pres\n                break\n\nFinal.iloc[100:150]\n\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\nGDP\nCPI\nPresident\nParty\n\n\n\n\n100\nDecember\n1952\n2.7\nNaN\n26.71\nHarry S Truman\nDemocratic\n\n\n101\nDecember\n1952\n2.7\nNaN\n26.71\nHarry S Truman\nDemocratic\n\n\n102\nFebruary\n1952\n3.1\nNaN\n26.41\nHarry S Truman\nDemocratic\n\n\n103\nFebruary\n1952\n3.1\nNaN\n26.41\nHarry S Truman\nDemocratic\n\n\n104\nJanuary\n1952\n3.2\n359.820\n26.45\nHarry S Truman\nDemocratic\n\n\n105\nJanuary\n1952\n3.2\n359.820\n26.45\nHarry S Truman\nDemocratic\n\n\n106\nJuly\n1952\n3.2\n367.701\n26.68\nHarry S Truman\nDemocratic\n\n\n107\nJuly\n1952\n3.2\n367.701\n26.68\nHarry S Truman\nDemocratic\n\n\n108\nJune\n1952\n3.0\nNaN\n26.53\nHarry S Truman\nDemocratic\n\n\n109\nJune\n1952\n3.0\nNaN\n26.53\nHarry S Truman\nDemocratic\n\n\n110\nMarch\n1952\n2.9\nNaN\n26.39\nHarry S Truman\nDemocratic\n\n\n111\nMarch\n1952\n2.9\nNaN\n26.39\nHarry S Truman\nDemocratic\n\n\n112\nMay\n1952\n3.0\nNaN\n26.47\nHarry S Truman\nDemocratic\n\n\n113\nMay\n1952\n3.0\nNaN\n26.47\nHarry S Truman\nDemocratic\n\n\n114\nNovember\n1952\n2.8\nNaN\n26.69\nHarry S Truman\nDemocratic\n\n\n115\nNovember\n1952\n2.8\nNaN\n26.69\nHarry S Truman\nDemocratic\n\n\n116\nOctober\n1952\n3.0\n380.812\n26.69\nHarry S Truman\nDemocratic\n\n\n117\nOctober\n1952\n3.0\n380.812\n26.69\nHarry S Truman\nDemocratic\n\n\n118\nSeptember\n1952\n3.1\nNaN\n26.63\nHarry S Truman\nDemocratic\n\n\n119\nSeptember\n1952\n3.1\nNaN\n26.63\nHarry S Truman\nDemocratic\n\n\n120\nApril\n1953\n2.7\n391.749\n26.69\nDwight D Eisenhower\nRepublican\n\n\n121\nApril\n1953\n2.7\n391.749\n26.69\nDwight D Eisenhower\nRepublican\n\n\n122\nAugust\n1953\n2.7\nNaN\n26.85\nDwight D Eisenhower\nRepublican\n\n\n123\nAugust\n1953\n2.7\nNaN\n26.85\nDwight D Eisenhower\nRepublican\n\n\n124\nDecember\n1953\n4.5\nNaN\n26.87\nDwight D Eisenhower\nRepublican\n\n\n125\nDecember\n1953\n4.5\nNaN\n26.87\nDwight D Eisenhower\nRepublican\n\n\n126\nFebruary\n1953\n2.6\nNaN\n26.59\nDwight D Eisenhower\nRepublican\n\n\n127\nFebruary\n1953\n2.6\nNaN\n26.59\nDwight D Eisenhower\nRepublican\n\n\n128\nJanuary\n1953\n2.9\n387.980\n26.64\nDwight D Eisenhower\nDemocratic\n\n\n129\nJanuary\n1953\n2.9\n387.980\n26.64\nDwight D Eisenhower\nDemocratic\n\n\n130\nJanuary\n1953\n2.9\n387.980\n26.64\nDwight D Eisenhower\nRepublican\n\n\n131\nJanuary\n1953\n2.9\n387.980\n26.64\nDwight D Eisenhower\nRepublican\n\n\n132\nJuly\n1953\n2.6\n391.171\n26.79\nDwight D Eisenhower\nRepublican\n\n\n133\nJuly\n1953\n2.6\n391.171\n26.79\nDwight D Eisenhower\nRepublican\n\n\n134\nJune\n1953\n2.5\nNaN\n26.77\nDwight D Eisenhower\nRepublican\n\n\n135\nJune\n1953\n2.5\nNaN\n26.77\nDwight D Eisenhower\nRepublican\n\n\n136\nMarch\n1953\n2.6\nNaN\n26.63\nDwight D Eisenhower\nRepublican\n\n\n137\nMarch\n1953\n2.6\nNaN\n26.63\nDwight D Eisenhower\nRepublican\n\n\n138\nMay\n1953\n2.5\nNaN\n26.70\nDwight D Eisenhower\nRepublican\n\n\n139\nMay\n1953\n2.5\nNaN\n26.70\nDwight D Eisenhower\nRepublican\n\n\n140\nNovember\n1953\n3.5\nNaN\n26.85\nDwight D Eisenhower\nRepublican\n\n\n141\nNovember\n1953\n3.5\nNaN\n26.85\nDwight D Eisenhower\nRepublican\n\n\n142\nOctober\n1953\n3.1\n385.970\n26.95\nDwight D Eisenhower\nRepublican\n\n\n143\nOctober\n1953\n3.1\n385.970\n26.95\nDwight D Eisenhower\nRepublican\n\n\n144\nSeptember\n1953\n2.9\nNaN\n26.89\nDwight D Eisenhower\nRepublican\n\n\n145\nSeptember\n1953\n2.9\nNaN\n26.89\nDwight D Eisenhower\nRepublican\n\n\n146\nApril\n1954\n5.9\n386.121\n26.86\nDwight D Eisenhower\nRepublican\n\n\n147\nApril\n1954\n5.9\n386.121\n26.86\nDwight D Eisenhower\nRepublican\n\n\n148\nAugust\n1954\n6.0\nNaN\n26.85\nDwight D Eisenhower\nRepublican\n\n\n149\nAugust\n1954\n6.0\nNaN\n26.85\nDwight D Eisenhower\nRepublican\n\n\n\n\n\n\n\n\n\nCode\nmonth_order = [\n    \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n    \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n]\nFinal[\"Month\"] = pd.Categorical(Final[\"Month\"], categories=month_order, ordered=True)\nFinal = Final.sort_values([\"Year\", \"Month\"]).reset_index(drop=True)\nFinal.head(20)\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\nGDP\nCPI\nPresident\nParty\n\n\n\n\n0\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n\n\n1\nJanuary\n1948\n3.4\n265.742\n23.68\nHarry S Truman\nDemocratic\n\n\n2\nFebruary\n1948\n3.8\nNaN\n23.67\nHarry S Truman\nDemocratic\n\n\n3\nFebruary\n1948\n3.8\nNaN\n23.67\nHarry S Truman\nDemocratic\n\n\n4\nMarch\n1948\n4.0\nNaN\n23.50\nHarry S Truman\nDemocratic\n\n\n5\nMarch\n1948\n4.0\nNaN\n23.50\nHarry S Truman\nDemocratic\n\n\n6\nApril\n1948\n3.9\n272.567\n23.82\nHarry S Truman\nDemocratic\n\n\n7\nApril\n1948\n3.9\n272.567\n23.82\nHarry S Truman\nDemocratic\n\n\n8\nMay\n1948\n3.5\nNaN\n24.01\nHarry S Truman\nDemocratic\n\n\n9\nMay\n1948\n3.5\nNaN\n24.01\nHarry S Truman\nDemocratic\n\n\n10\nJune\n1948\n3.6\nNaN\n24.15\nHarry S Truman\nDemocratic\n\n\n11\nJune\n1948\n3.6\nNaN\n24.15\nHarry S Truman\nDemocratic\n\n\n12\nJuly\n1948\n3.6\n279.196\n24.40\nHarry S Truman\nDemocratic\n\n\n13\nJuly\n1948\n3.6\n279.196\n24.40\nHarry S Truman\nDemocratic\n\n\n14\nAugust\n1948\n3.9\nNaN\n24.43\nHarry S Truman\nDemocratic\n\n\n15\nAugust\n1948\n3.9\nNaN\n24.43\nHarry S Truman\nDemocratic\n\n\n16\nSeptember\n1948\n3.8\nNaN\n24.36\nHarry S Truman\nDemocratic\n\n\n17\nSeptember\n1948\n3.8\nNaN\n24.36\nHarry S Truman\nDemocratic\n\n\n18\nOctober\n1948\n3.7\n280.366\n24.31\nHarry S Truman\nDemocratic\n\n\n19\nOctober\n1948\n3.7\n280.366\n24.31\nHarry S Truman\nDemocratic\n\n\n\n\n\n\n\n\n\nCode\nFinal = Final.drop_duplicates()\nFinal.tail()\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\nGDP\nCPI\nPresident\nParty\n\n\n\n\n1787\nJuly\n2025\n4.2\nNaN\n322.132\nDonald Trump\nRepublican\n\n\n1788\nAugust\n2025\n4.3\nNaN\n323.364\nDonald Trump\nRepublican\n\n\n1789\nSeptember\n2025\n4.4\nNaN\n324.368\nDonald Trump\nRepublican\n\n\n1790\nOctober\n2025\nNaN\nNaN\nNaN\nDonald Trump\nRepublican\n\n\n1791\nNovember\n2025\nNaN\nNaN\nNaN\nDonald Trump\nRepublican\n\n\n\n\n\n\n\n\n\nCode\n# Filling in the missing data with the mean of the previous and next known values\nFinal[\"GDP\"] = Final[\"GDP\"].interpolate(method=\"linear\") \\\n                           .ffill()\nFinal = Final.iloc[:-2]\nFinal.head(100)\n\n\n\n\n\n\n\n\n\nMonth\nYear\nUNRATE\nGDP\nCPI\nPresident\nParty\n\n\n\n\n0\nJanuary\n1948\n3.4\n265.742000\n23.68\nHarry S Truman\nDemocratic\n\n\n2\nFebruary\n1948\n3.8\n268.017000\n23.67\nHarry S Truman\nDemocratic\n\n\n4\nMarch\n1948\n4.0\n270.292000\n23.50\nHarry S Truman\nDemocratic\n\n\n6\nApril\n1948\n3.9\n272.567000\n23.82\nHarry S Truman\nDemocratic\n\n\n8\nMay\n1948\n3.5\n274.776667\n24.01\nHarry S Truman\nDemocratic\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n190\nNovember\n1955\n4.2\n437.976667\n26.88\nDwight D Eisenhower\nRepublican\n\n\n192\nDecember\n1955\n4.2\n438.861333\n26.87\nDwight D Eisenhower\nRepublican\n\n\n194\nJanuary\n1956\n4.0\n439.746000\n26.83\nDwight D Eisenhower\nRepublican\n\n\n196\nFebruary\n1956\n3.9\n441.834000\n26.86\nDwight D Eisenhower\nRepublican\n\n\n198\nMarch\n1956\n4.2\n443.922000\n26.89\nDwight D Eisenhower\nRepublican\n\n\n\n\n100 rows  7 columns\n\n\n\n\n\nCode\nFinal.to_csv(\"../data/raw/econ_data.csv\")"
  }
]